interactions:
- request:
    body: '{"post":[{"id":"035c6a6c-6a50-4ca7-9b07-9f573386f3cd","start_time":"2024-09-19T18:09:56.253986+00:00","end_time":null,"extra":{"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.123","library":"langchain-core","platform":"macOS-14.5-arm64-arm-64bit","runtime":"python","py_implementation":"CPython","runtime_version":"3.12.4","langchain_version":"0.3.0","langchain_core_version":"0.3.1","library_version":"0.3.1"},"metadata":{"revision_id":"checkpoint==1.0.10-68-g22fa527b-dirty"}},"error":null,"events":[{"name":"start","time":"2024-09-19T18:09:56.253986+00:00"}],"reference_example_id":null,"parent_run_id":null,"tags":[],"trace_id":"035c6a6c-6a50-4ca7-9b07-9f573386f3cd","dotted_order":"20240919T180956253986Z035c6a6c-6a50-4ca7-9b07-9f573386f3cd","outputs":null,"session_name":"default","name":"RunnableSequence","inputs":{"question":"agent
      memory"},"run_type":"chain"},{"id":"f79c5a6c-ebb4-4b6d-9d36-97015ee41c4e","start_time":"2024-09-19T18:09:56.254526+00:00","end_time":"2024-09-19T18:09:56.254733+00:00","extra":{"metadata":{"revision_id":"checkpoint==1.0.10-68-g22fa527b-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.123","library":"langsmith","platform":"macOS-14.5-arm64-arm-64bit","runtime":"python","py_implementation":"CPython","runtime_version":"3.12.4","langchain_version":"0.3.0","langchain_core_version":"0.3.1"}},"error":null,"serialized":{"lc":1,"type":"constructor","id":["langchain","prompts","prompt","PromptTemplate"],"kwargs":{"input_variables":["question"],"template":"You
      a question re-writer that converts an input question to a better version that
      is optimized \n \n         for vectorstore retrieval. Look at the initial and
      formulate an improved question. \n\n         Here is the initial question: \n\n
      {question}. Improved question with no preamble: \n ","template_format":"f-string"},"name":"PromptTemplate"},"events":[{"name":"start","time":"2024-09-19T18:09:56.254526+00:00"},{"name":"end","time":"2024-09-19T18:09:56.254733+00:00"}],"reference_example_id":null,"parent_run_id":"035c6a6c-6a50-4ca7-9b07-9f573386f3cd","tags":["seq:step:1"],"trace_id":"035c6a6c-6a50-4ca7-9b07-9f573386f3cd","dotted_order":"20240919T180956253986Z035c6a6c-6a50-4ca7-9b07-9f573386f3cd.20240919T180956254526Zf79c5a6c-ebb4-4b6d-9d36-97015ee41c4e","outputs":{"output":{"text":"You
      a question re-writer that converts an input question to a better version that
      is optimized \n \n         for vectorstore retrieval. Look at the initial and
      formulate an improved question. \n\n         Here is the initial question: \n\n
      agent memory. Improved question with no preamble: \n ","type":"StringPromptValue"}},"session_name":"default","name":"PromptTemplate","inputs":{"question":"agent
      memory"},"run_type":"prompt"},{"id":"2027c403-d089-4bd2-b580-d02005466aca","start_time":"2024-09-19T18:09:56.254953+00:00","end_time":null,"extra":{"invocation_params":{"model":"mistral","format":null,"options":{"mirostat":null,"mirostat_eta":null,"mirostat_tau":null,"num_ctx":null,"num_gpu":null,"num_thread":null,"num_predict":null,"repeat_last_n":null,"repeat_penalty":null,"temperature":0.0,"stop":null,"tfs_z":null,"top_k":null,"top_p":null},"system":null,"template":null,"keep_alive":null,"raw":null,"_type":"ollama-chat","stop":null},"options":{"stop":null},"batch_size":1,"metadata":{"ls_provider":"ollama","ls_model_name":"mistral","ls_model_type":"chat","ls_temperature":0.0,"revision_id":"checkpoint==1.0.10-68-g22fa527b-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.123","library":"langchain-core","platform":"macOS-14.5-arm64-arm-64bit","runtime":"python","py_implementation":"CPython","runtime_version":"3.12.4","langchain_version":"0.3.0","langchain_core_version":"0.3.1","library_version":"0.3.1"}},"error":null,"serialized":{"lc":1,"type":"not_implemented","id":["langchain_community","chat_models","ollama","ChatOllama"],"repr":"ChatOllama(model=''mistral'',
      temperature=0.0)","name":"ChatOllama"},"events":[{"name":"start","time":"2024-09-19T18:09:56.254953+00:00"}],"reference_example_id":null,"parent_run_id":"035c6a6c-6a50-4ca7-9b07-9f573386f3cd","tags":["seq:step:2"],"trace_id":"035c6a6c-6a50-4ca7-9b07-9f573386f3cd","dotted_order":"20240919T180956253986Z035c6a6c-6a50-4ca7-9b07-9f573386f3cd.20240919T180956254953Z2027c403-d089-4bd2-b580-d02005466aca","outputs":null,"session_name":"default","name":"ChatOllama","inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"You
      a question re-writer that converts an input question to a better version that
      is optimized \n \n         for vectorstore retrieval. Look at the initial and
      formulate an improved question. \n\n         Here is the initial question: \n\n
      agent memory. Improved question with no preamble: \n ","type":"human"}}]]},"run_type":"llm"}]}'
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '4812'
      Content-Type:
      - application/json
      User-Agent:
      - langsmith-py/0.1.123
    method: POST
    uri: https://api.smith.langchain.com/runs/batch
  response:
    body:
      string: '{"detail":"Monthly unique traces usage limit exceeded"}'
    headers:
      Access-Control-Allow-Credentials:
      - 'true'
      Access-Control-Allow-Headers:
      - '*'
      Access-Control-Allow-Methods:
      - '*'
      Access-Control-Allow-Origin:
      - ''
      Access-Control-Expose-Headers:
      - '*'
      Access-Control-Max-Age:
      - '600'
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Length:
      - '55'
      Via:
      - 1.1 google
      content-type:
      - application/json
      date:
      - Thu, 19 Sep 2024 18:09:56 GMT
      server:
      - uvicorn
    status:
      code: 429
      message: Too Many Requests
- request:
    body: '{"messages": [{"role": "user", "content": "You a question re-writer that
      converts an input question to a better version that is optimized \n \n         for
      vectorstore retrieval. Look at the initial and formulate an improved question.
      \n\n         Here is the initial question: \n\n agent memory. Improved question
      with no preamble: \n ", "images": []}], "model": "mistral", "format": null,
      "options": {"mirostat": null, "mirostat_eta": null, "mirostat_tau": null, "num_ctx":
      null, "num_gpu": null, "num_thread": null, "num_predict": null, "repeat_last_n":
      null, "repeat_penalty": null, "temperature": 0.0, "stop": null, "tfs_z": null,
      "top_k": null, "top_p": null}, "system": null, "template": null, "keep_alive":
      null, "raw": null}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '733'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.32.3
    method: POST
    uri: http://localhost:11434/api/chat
  response:
    body:
      string: '{"model":"mistral","created_at":"2024-09-19T18:09:56.490528Z","message":{"role":"assistant","content":"
        What"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.526779Z","message":{"role":"assistant","content":"
        is"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.56716Z","message":{"role":"assistant","content":"
        the"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.605395Z","message":{"role":"assistant","content":"
        function"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.639766Z","message":{"role":"assistant","content":"
        of"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.673882Z","message":{"role":"assistant","content":"
        an"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.708061Z","message":{"role":"assistant","content":"
        agent"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.743217Z","message":{"role":"assistant","content":"''"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.77823Z","message":{"role":"assistant","content":"s"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.812439Z","message":{"role":"assistant","content":"
        memory"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.848089Z","message":{"role":"assistant","content":"
        in"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.88309Z","message":{"role":"assistant","content":"
        a"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.918431Z","message":{"role":"assistant","content":"
        given"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.955684Z","message":{"role":"assistant","content":"
        context"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:56.991705Z","message":{"role":"assistant","content":"?"},"done":false}

        {"model":"mistral","created_at":"2024-09-19T18:09:57.027607Z","message":{"role":"assistant","content":""},"done_reason":"stop","done":true,"total_duration":769717167,"load_duration":10399125,"prompt_eval_count":75,"prompt_eval_duration":220379000,"eval_count":16,"eval_duration":537033000}

        '
    headers:
      Content-Type:
      - application/x-ndjson
      Date:
      - Thu, 19 Sep 2024 18:09:56 GMT
      Transfer-Encoding:
      - chunked
    status:
      code: 200
      message: OK
version: 1
