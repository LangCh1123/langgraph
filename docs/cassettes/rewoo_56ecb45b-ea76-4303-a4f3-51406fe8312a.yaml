interactions:
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - langsmith-py/0.1.123
    method: GET
    uri: https://api.smith.langchain.com/info
  response:
    body:
      string: '{"version":"0.7.29","license_expiration_time":null,"batch_ingest_config":{"scale_up_qsize_trigger":1000,"scale_up_nthreads_limit":16,"scale_down_nempty_trigger":4,"size_limit":100,"size_limit_bytes":20971520},"instance_flags":{"generate_ai_query_enabled":true,"org_creation_disabled":false,"show_ttl_ui":true,"trace_tier_duration_days":{"longlived":400,"shortlived":14},"search_enabled":true,"workspace_scope_org_invites":false,"s3_storage_enabled":true}}'
    headers:
      Access-Control-Allow-Credentials:
      - 'true'
      Access-Control-Allow-Headers:
      - '*'
      Access-Control-Allow-Methods:
      - '*'
      Access-Control-Allow-Origin:
      - ''
      Access-Control-Expose-Headers:
      - '*'
      Access-Control-Max-Age:
      - '600'
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Length:
      - '455'
      Via:
      - 1.1 google
      cache-control:
      - no-cache
      content-type:
      - application/json
      date:
      - Thu, 19 Sep 2024 18:04:14 GMT
      server:
      - uvicorn
    status:
      code: 200
      message: OK
- request:
    body: "{\"post\":[{\"id\":\"1c73ced7-13af-4676-89db-106a69330079\",\"start_time\":\"2024-09-19T18:04:14.967833+00:00\",\"end_time\":null,\"extra\":{\"invocation_params\":{\"model\":\"gpt-4o\",\"model_name\":\"gpt-4o\",\"stream\":false,\"n\":1,\"temperature\":0.7,\"_type\":\"openai-chat\",\"stop\":null},\"options\":{\"stop\":null},\"batch_size\":1,\"metadata\":{\"ls_provider\":\"openai\",\"ls_model_name\":\"gpt-4o\",\"ls_model_type\":\"chat\",\"ls_temperature\":0.7,\"revision_id\":\"checkpoint==1.0.10-68-g22fa527b-dirty\"},\"runtime\":{\"sdk\":\"langsmith-py\",\"sdk_version\":\"0.1.123\",\"library\":\"langchain-core\",\"platform\":\"macOS-14.5-arm64-arm-64bit\",\"runtime\":\"python\",\"py_implementation\":\"CPython\",\"runtime_version\":\"3.12.4\",\"langchain_version\":\"0.3.0\",\"langchain_core_version\":\"0.3.1\",\"library_version\":\"0.3.1\"}},\"error\":null,\"serialized\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"chat_models\",\"openai\",\"ChatOpenAI\"],\"kwargs\":{\"model_name\":\"gpt-4o\",\"temperature\":0.7,\"openai_api_key\":{\"lc\":1,\"type\":\"secret\",\"id\":[\"OPENAI_API_KEY\"]},\"max_retries\":2,\"n\":1},\"name\":\"ChatOpenAI\"},\"events\":[{\"name\":\"start\",\"time\":\"2024-09-19T18:04:14.967833+00:00\"}],\"reference_example_id\":null,\"parent_run_id\":null,\"tags\":[],\"trace_id\":\"1c73ced7-13af-4676-89db-106a69330079\",\"dotted_order\":\"20240919T180414967833Z1c73ced7-13af-4676-89db-106a69330079\",\"outputs\":null,\"session_name\":\"default\",\"name\":\"ChatOpenAI\",\"inputs\":{\"messages\":[[{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"schema\",\"messages\",\"HumanMessage\"],\"kwargs\":{\"content\":\"For
      the following task, make plans that can solve the problem step by step. For
      each plan, indicate     which external tool together with tool input to retrieve
      evidence. You can store the evidence into a     variable #E that can be called
      by later tools. (Plan, #E1, Plan, #E2, Plan, ...)\\n    \\n    Tools can be
      one of the following:\\n    (1) Google[input]: Worker that searches results
      from Google. Useful when you need to find short\\n    and succinct answers about
      a specific topic. The input should be a search query.\\n    (2) LLM[input]:
      A pretrained LLM like yourself. Useful when you need to act with general\\n
      \   world knowledge and common sense. Prioritize it when you are confident in
      solving the problem\\n    yourself. Input can be any instruction.\\n    \\n
      \   For example,\\n    Task: Thomas, Toby, and Rebecca worked a total of 157
      hours in one week. Thomas worked x\\n    hours. Toby worked 10 hours less than
      twice what Thomas worked, and Rebecca worked 8 hours\\n    less than Toby. How
      many hours did Rebecca work?\\n    Plan: Given Thomas worked x hours, translate
      the problem into algebraic expressions and solve\\n    with Wolfram Alpha. #E1
      = WolframAlpha[Solve x + (2x \u2212 10) + ((2x \u2212 10) \u2212 8) = 157]\\n
      \   Plan: Find out the number of hours Thomas worked. #E2 = LLM[What is x, given
      #E1]\\n    Plan: Calculate the number of hours Rebecca worked. #E3 = Calculator[(2
      \u2217 #E2 \u2212 10) \u2212 8]\\n    \\n    Begin! \\n    Describe your plans
      with rich details. Each Plan should be followed by only one #E.\\n    \\n    Task:
      what is the exact hometown of the 2024 mens australian open winner\",\"type\":\"human\"}}]]},\"run_type\":\"llm\"}]}"
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '3101'
      Content-Type:
      - application/json
      User-Agent:
      - langsmith-py/0.1.123
    method: POST
    uri: https://api.smith.langchain.com/runs/batch
  response:
    body:
      string: '{"detail":"Monthly unique traces usage limit exceeded"}'
    headers:
      Access-Control-Allow-Credentials:
      - 'true'
      Access-Control-Allow-Headers:
      - '*'
      Access-Control-Allow-Methods:
      - '*'
      Access-Control-Allow-Origin:
      - ''
      Access-Control-Expose-Headers:
      - '*'
      Access-Control-Max-Age:
      - '600'
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Length:
      - '55'
      Via:
      - 1.1 google
      content-type:
      - application/json
      date:
      - Thu, 19 Sep 2024 18:04:14 GMT
      server:
      - uvicorn
    status:
      code: 429
      message: Too Many Requests
- request:
    body: '{"messages": [{"content": "For the following task, make plans that can
      solve the problem step by step. For each plan, indicate     which external tool
      together with tool input to retrieve evidence. You can store the evidence into
      a     variable #E that can be called by later tools. (Plan, #E1, Plan, #E2,
      Plan, ...)\n    \n    Tools can be one of the following:\n    (1) Google[input]:
      Worker that searches results from Google. Useful when you need to find short\n    and
      succinct answers about a specific topic. The input should be a search query.\n    (2)
      LLM[input]: A pretrained LLM like yourself. Useful when you need to act with
      general\n    world knowledge and common sense. Prioritize it when you are confident
      in solving the problem\n    yourself. Input can be any instruction.\n    \n    For
      example,\n    Task: Thomas, Toby, and Rebecca worked a total of 157 hours in
      one week. Thomas worked x\n    hours. Toby worked 10 hours less than twice what
      Thomas worked, and Rebecca worked 8 hours\n    less than Toby. How many hours
      did Rebecca work?\n    Plan: Given Thomas worked x hours, translate the problem
      into algebraic expressions and solve\n    with Wolfram Alpha. #E1 = WolframAlpha[Solve
      x + (2x \u2212 10) + ((2x \u2212 10) \u2212 8) = 157]\n    Plan: Find out the
      number of hours Thomas worked. #E2 = LLM[What is x, given #E1]\n    Plan: Calculate
      the number of hours Rebecca worked. #E3 = Calculator[(2 \u2217 #E2 \u2212 10)
      \u2212 8]\n    \n    Begin! \n    Describe your plans with rich details. Each
      Plan should be followed by only one #E.\n    \n    Task: what is the exact hometown
      of the 2024 mens australian open winner", "role": "user"}], "model": "gpt-4o",
      "n": 1, "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1730'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//dFLLbtswELz7KxbMIRcrkBXLjoW2gJumTYG2aS/tITIEWlrJTMmlQK6T
        uIH/PdDDsnvIhQBndmeGu3wZAQhViAREvpGcm1oHy8VnetD/zO9venm1K39d397OrvkjF+7ucS7G
        TYddP2DOh66L3JpaIytLHZ07lIyN6mQezeazRRjHLWFsgbppq2oOpjaIwmgahHEwuewbN1bl6EUC
        9yMAgJf2bCJSgc8igXB8QAx6LysUyVAEIJzVDSKk98qzJBbjI5lbYqQ29U8tKYGvBRKrcge8QXhS
        ROjAlu2tCQbfkc49LLeendRKEtzVSBeQ0tnNBN7DF2srjfepeLu4V03FKqWUOtdPyOiMImyN8Fnm
        DBtrkO0THez7MKoLqLAARXB2M+nMo1Pzd3/a2nMPP6TBD4NUKlanj3dYbr1sZk9brXt8P0xT26p2
        du17fsBLRcpvMofSW2om59nWomX3I4BVu7Xtf4sQtbOm5oztX6RG8HKx6PTE8Z8c2Xjek2xZ6iM+
        jWdvdWUFslTan+xedAkVVUeFcIjZvlP4nWc0WamoQlc71X2Fss7iSM7LabgO12K0H70CAAD//wMA
        ulHDgxMDAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b7f425f8f9854-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:04:15 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=MKdZUYsAsmxWJDSDAB4W97FGI0lZ_Y1EBR0ap7PI_70-1726769055-1.0.1.1-9SRGde.JGk3gxT3PQfXU4gkgtBSvbdftPo9pSwVq5SlwKZ.Nr6pZnvxxsDXQqPHHSeeoADyGTyYrZXJ8vAgYHA;
        path=/; expires=Thu, 19-Sep-24 18:34:15 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=FHbrAPpE1PxSBfFkrIJ4zn5wYl13Y1cOXzQ8zWOq0U4-1726769055918-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '602'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999588'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_fe461c8f75aea75719a5124ed2387641
    status:
      code: 200
      message: OK
version: 1
