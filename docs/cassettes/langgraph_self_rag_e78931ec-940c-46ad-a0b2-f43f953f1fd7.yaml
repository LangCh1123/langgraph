interactions:
- request:
    body: '{"messages": [{"content": "You are a grader assessing whether an LLM generation
      is grounded in / supported by a set of retrieved facts. \n \n         Give a
      binary score ''yes'' or ''no''. ''Yes'' means that the answer is grounded in
      / supported by the set of facts.", "role": "system"}, {"content": "Set of facts:
      \n\n [Document(metadata={''description'': ''Building agents with LLM (large
      language model) as its core controller is a cool concept. Several proof-of-concepts
      demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples.
      The potentiality of LLM extends beyond generating well-written copies, stories,
      essays and programs; it can be framed as a powerful general problem solver.\\nAgent
      System Overview In a LLM-powered autonomous agent system, LLM functions as the
      agent\u2019s brain, complemented by several key components:'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-06-23-agent/'',
      ''title'': \"LLM Powered Autonomous Agents | Lil''Log\"}, page_content=''They
      also discussed the risks, especially with illicit drugs and bioweapons. They
      developed a test set containing a list of known chemical weapon agents and asked
      the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain
      a synthesis solution and the agent attempted to consult documentation to execute
      the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5
      happened after a Web search while 2 were rejected based on prompt only.\\nGenerative
      Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment
      where 25 virtual characters, each controlled by a LLM-powered agent, are living
      and interacting in a sandbox environment, inspired by The Sims. Generative agents
      create believable simulacra of human behavior for interactive applications.\\nThe
      design of generative agents combines LLM with memory, planning and reflection
      mechanisms to enable agents to behave conditioned on past experience, as well
      as to interact with other agents.\\n\\nMemory stream: is a long-term memory
      module (external database) that records a comprehensive list of agents\u2019
      experience in natural language.''), Document(metadata={''description'': ''Building
      agents with LLM (large language model) as its core controller is a cool concept.
      Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI,
      serve as inspiring examples. The potentiality of LLM extends beyond generating
      well-written copies, stories, essays and programs; it can be framed as a powerful
      general problem solver.\\nAgent System Overview In a LLM-powered autonomous
      agent system, LLM functions as the agent\u2019s brain, complemented by several
      key components:'', ''language'': ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-06-23-agent/'',
      ''title'': \"LLM Powered Autonomous Agents | Lil''Log\"}, page_content=''Building
      agents with LLM (large language model) as its core controller is a cool concept.
      Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI,
      serve as inspiring examples. The potentiality of LLM extends beyond generating
      well-written copies, stories, essays and programs; it can be framed as a powerful
      general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous
      agent system, LLM functions as the agent\u2019s brain, complemented by several
      key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks
      down large tasks into smaller, manageable subgoals, enabling efficient handling
      of complex tasks.\\nReflection and refinement: The agent can do self-criticism
      and self-reflection over past actions, learn from mistakes and refine them for
      future steps, thereby improving the quality of final results.\\n\\n\\nMemory''),
      Document(metadata={''description'': ''Building agents with LLM (large language
      model) as its core controller is a cool concept. Several proof-of-concepts demos,
      such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The
      potentiality of LLM extends beyond generating well-written copies, stories,
      essays and programs; it can be framed as a powerful general problem solver.\\nAgent
      System Overview In a LLM-powered autonomous agent system, LLM functions as the
      agent\u2019s brain, complemented by several key components:'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-06-23-agent/'',
      ''title'': \"LLM Powered Autonomous Agents | Lil''Log\"}, page_content=''Resources:\\n1.
      Internet access for searches and information gathering.\\n2. Long Term memory
      management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4.
      File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze
      your actions to ensure you are performing to the best of your abilities.\\n2.
      Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect
      on past decisions and strategies to refine your approach.\\n4. Every command
      has a cost, so be smart and efficient. Aim to complete tasks in the least number
      of steps.''), Document(metadata={''description'': ''Building agents with LLM
      (large language model) as its core controller is a cool concept. Several proof-of-concepts
      demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples.
      The potentiality of LLM extends beyond generating well-written copies, stories,
      essays and programs; it can be framed as a powerful general problem solver.\\nAgent
      System Overview In a LLM-powered autonomous agent system, LLM functions as the
      agent\u2019s brain, complemented by several key components:'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-06-23-agent/'',
      ''title'': \"LLM Powered Autonomous Agents | Lil''Log\"}, page_content=''Short-term
      memory: I would consider all the in-context learning (See Prompt Engineering)
      as utilizing short-term memory of the model to learn.\\nLong-term memory: This
      provides the agent with the capability to retain and recall (infinite) information
      over extended periods, often by leveraging an external vector store and fast
      retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for
      extra information that is missing from the model weights (often hard to change
      after pre-training), including current information, code execution capability,
      access to proprietary information sources and more.'')] \n\n LLM generation:
      The agent system overview includes components like planning, subgoal decomposition,
      reflection, and refinement. Generative agents combine LLM with memory, planning,
      and reflection mechanisms for behavior conditioning. Memory includes long-term
      memory for recording agents'' experiences.", "role": "user"}], "model": "gpt-3.5-turbo-0125",
      "n": 1, "parallel_tool_calls": false, "stream": false, "temperature": 0.0, "tool_choice":
      {"type": "function", "function": {"name": "GradeHallucinations"}}, "tools":
      [{"type": "function", "function": {"name": "GradeHallucinations", "description":
      "Binary score for hallucination present in generation answer.", "parameters":
      {"properties": {"binary_score": {"description": "Answer is grounded in the facts,
      ''yes'' or ''no''", "type": "string"}}, "required": ["binary_score"], "type":
      "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '7156'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RSXWvbMBR9968Q9zkp+Wqy+C2FZRsNBMpoB8swinzjKJElIV13NSH/fchObCes
        ehDiHp1z7tcpYgxkCjEDseckcqv6i/mSDkdepE9LOgy/cvOuXqQVq+WPj/UX6AWG2R5Q0JX1IExu
        FZI0uoaFQ04YVIez0XQ2nU9GswrITYoq0DJL/fHDY58KtzX9wXD0eGHujRToIWa/I8YYO1V3yFGn
        +AExG/SukRy95xlC3HxiDJxRIQLce+mJa4JeCwqjCXVIWxdKdQAyRiWCK9Ua1+fUebeN4kolv+bl
        aj3+uX59eRbTxevbcbD4O1mlbx2/Wrq0VUK7QoumQR28icd3ZoyB5nnF/eZ4it+5UoWQmoff/k6G
        MeAuK3LUFEqA0wa2UnNXJl4YhxuIN1Ci38AZbnjn6H/vP53WONwVnqtLzy7xczMEZTLrzNbf9RR2
        Uku/TxxyX9UGnoytvYNP5QDFzfzAOpNbSsgcUQfB4WQ2rgWhXbAWnl4wMsTVDWv+GStJkbisptws
        Vp2i1FkrMWjyrAoFX3rCPNlJnaGzTjYrFJ2jfwAAAP//AwDIxQ/YQQMAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b88592f0ef9fd-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:27 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=gbPqaEJus6B8nD2cBtfP2g2BPwKfHnA9_6FUPIg5zVc-1726769427-1.0.1.1-RalIslv5lLJG0mrroEjFf70jWJLARn.SQmLnyRRhYRxpus.TOY84gseykdUBXDzy.oalPXMIEmMmZIqpcHluvg;
        path=/; expires=Thu, 19-Sep-24 18:40:27 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=NnbdmQNsKGwzUzphwZ0sglAc80q8325mSK67ocIDIyc-1726769427887-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '261'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998361'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_5fb219c97fe59f50ec16af6793064a6e
    status:
      code: 200
      message: OK
version: 1
