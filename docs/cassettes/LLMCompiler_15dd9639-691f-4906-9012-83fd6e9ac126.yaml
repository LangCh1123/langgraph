interactions:
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - langsmith-py/0.1.123
    method: GET
    uri: https://api.smith.langchain.com/info
  response:
    body:
      string: '{"version":"0.7.29","license_expiration_time":null,"batch_ingest_config":{"scale_up_qsize_trigger":1000,"scale_up_nthreads_limit":16,"scale_down_nempty_trigger":4,"size_limit":100,"size_limit_bytes":20971520},"instance_flags":{"generate_ai_query_enabled":true,"org_creation_disabled":false,"show_ttl_ui":true,"trace_tier_duration_days":{"longlived":400,"shortlived":14},"search_enabled":true,"workspace_scope_org_invites":false,"s3_storage_enabled":true}}'
    headers:
      Access-Control-Allow-Credentials:
      - 'true'
      Access-Control-Allow-Headers:
      - '*'
      Access-Control-Allow-Methods:
      - '*'
      Access-Control-Allow-Origin:
      - ''
      Access-Control-Expose-Headers:
      - '*'
      Access-Control-Max-Age:
      - '600'
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Length:
      - '455'
      Via:
      - 1.1 google
      cache-control:
      - no-cache
      content-type:
      - application/json
      date:
      - Thu, 19 Sep 2024 18:11:45 GMT
      server:
      - uvicorn
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - langsmith-py/0.1.123
    method: GET
    uri: https://api.smith.langchain.com/commits/wfh/llm-compiler/latest
  response:
    body:
      string: '{"commit_hash":"24623d82475c1ceedb479352cc401d385b7714a238d8b0b8189ed4c7884865fb","manifest":{"id":["langchain","prompts","chat","ChatPromptTemplate"],"lc":1,"type":"constructor","kwargs":{"messages":[{"id":["langchain","prompts","chat","SystemMessagePromptTemplate"],"lc":1,"type":"constructor","kwargs":{"prompt":{"id":["langchain","prompts","prompt","PromptTemplate"],"lc":1,"type":"constructor","kwargs":{"template":"Given
        a user query, create a plan to solve it with the utmost parallelizability.
        Each plan should comprise an action from the following {num_tools} types:\n{tool_descriptions}\n{num_tools}.
        join(): Collects and combines results from prior actions.\n\n - An LLM agent
        is called upon invoking join() to either finalize the user query or wait until
        the plans are executed.\n - join should always be the last action in the plan,
        and will be called in two scenarios:\n   (a) if the answer can be determined
        by gathering the outputs from tasks to generate the final response.\n   (b)
        if the answer cannot be determined in the planning phase before you execute
        the plans. Guidelines:\n - Each action described above contains input/output
        types and description.\n    - You must strictly adhere to the input and output
        types for each action.\n    - The action descriptions contain the guidelines.
        You MUST strictly follow those guidelines when you use the actions.\n - Each
        action in the plan should strictly be one of the above types. Follow the Python
        conventions for each action.\n - Each action MUST have a unique ID, which
        is strictly increasing.\n - Inputs for actions can either be constants or
        outputs from preceding actions. In the latter case, use the format $id to
        denote the ID of the previous action whose output will be the input.\n - Always
        call join as the last action in the plan. Say ''<END_OF_PLAN>'' after you
        call join\n - Ensure the plan maximizes parallelizability.\n - Only use the
        provided action types. If a query cannot be addressed using these, invoke
        the join action for the next steps.\n - Never introduce new actions other
        than the ones provided.","input_variables":["num_tools","tool_descriptions"],"template_format":"f-string"}}}},{"id":["langchain_core","prompts","chat","MessagesPlaceholder"],"lc":1,"type":"constructor","kwargs":{"variable_name":"messages"}},{"id":["langchain","prompts","chat","SystemMessagePromptTemplate"],"lc":1,"type":"constructor","kwargs":{"prompt":{"id":["langchain","prompts","prompt","PromptTemplate"],"lc":1,"type":"constructor","kwargs":{"template":"Remember,
        ONLY respond with the task list in the correct format! E.g.:\nidx. tool(arg_name=args)","input_variables":[],"template_format":"f-string"}}}}],"input_variables":["num_tools","tool_descriptions","messages"],"partial_variables":{}}},"examples":[]}'
    headers:
      Access-Control-Allow-Credentials:
      - 'true'
      Access-Control-Allow-Headers:
      - '*'
      Access-Control-Allow-Methods:
      - '*'
      Access-Control-Allow-Origin:
      - ''
      Access-Control-Expose-Headers:
      - '*'
      Access-Control-Max-Age:
      - '600'
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Length:
      - '2780'
      Via:
      - 1.1 google
      cache-control:
      - no-cache
      content-type:
      - application/json
      date:
      - Thu, 19 Sep 2024 18:11:46 GMT
      server:
      - uvicorn
    status:
      code: 200
      message: OK
version: 1
