interactions:
- request:
    body: '{"messages": [{"content": "Given a user query, create a plan to solve it
      with the utmost parallelizability. Each plan should comprise an action from
      the following 3 types:\n1. tavily_search_results_json(query=\"the search query\")
      - a search engine.\n\n2. math(problem: str, context: Optional[list[str]]) ->
      float:\n - Solves the provided math problem.\n - `problem` can be either a simple
      math problem (e.g. \"1 + 3\") or a word problem (e.g. \"how many apples are
      there if there are 3 apples and 2 apples\").\n - You cannot calculate multiple
      expressions in one call. For instance, `math(''1 + 3, 2 + 4'')` does not work.
      If you need to calculate multiple expressions, you need to call them separately
      like `math(''1 + 3'')` and then `math(''2 + 4'')`\n - Minimize the number of
      `math` actions as much as possible. For instance, instead of calling 2. math(\"what
      is the 10% of $1\") and then call 3. math(\"$1 + $2\"), you MUST call 2. math(\"what
      is the 110% of $1\") instead, which will reduce the number of math actions.\n
      - You can optionally provide a list of strings as `context` to help the agent
      solve the problem. If there are multiple contexts you need to answer the question,
      you can provide them as a list of strings.\n - `math` action will not see the
      output of the previous actions unless you provide it as `context`. You MUST
      provide the output of the previous actions as `context` if you need to do math
      on it.\n - You MUST NEVER provide `search` type action''s outputs as a variable
      in the `problem` argument. This is because `search` returns a text blob that
      contains the information about the entity, not a number or value. Therefore,
      when you need to provide an output of `search` action, you MUST provide it as
      a `context` argument to `math` action. For example, 1. search(\"Barack Obama\")
      and then 2. math(\"age of $1\") is NEVER allowed. Use 2. math(\"age of Barack
      Obama\", context=[\"$1\"]) instead.\n - When you ask a question about `context`,
      specify the units. For instance, \"what is xx in height?\" or \"what is xx in
      millions?\" instead of \"what is xx?\"\n\n3. join(): Collects and combines results
      from prior actions.\n\n - An LLM agent is called upon invoking join() to either
      finalize the user query or wait until the plans are executed.\n - join should
      always be the last action in the plan, and will be called in two scenarios:\n   (a)
      if the answer can be determined by gathering the outputs from tasks to generate
      the final response.\n   (b) if the answer cannot be determined in the planning
      phase before you execute the plans. Guidelines:\n - Each action described above
      contains input/output types and description.\n    - You must strictly adhere
      to the input and output types for each action.\n    - The action descriptions
      contain the guidelines. You MUST strictly follow those guidelines when you use
      the actions.\n - Each action in the plan should strictly be one of the above
      types. Follow the Python conventions for each action.\n - Each action MUST have
      a unique ID, which is strictly increasing.\n - Inputs for actions can either
      be constants or outputs from preceding actions. In the latter case, use the
      format $id to denote the ID of the previous action whose output will be the
      input.\n - Always call join as the last action in the plan. Say ''<END_OF_PLAN>''
      after you call join\n - Ensure the plan maximizes parallelizability.\n - Only
      use the provided action types. If a query cannot be addressed using these, invoke
      the join action for the next steps.\n - Never introduce new actions other than
      the ones provided.", "role": "system"}, {"content": "Find the current temperature
      in Tokyo, then, respond with a flashcard summarizing this information", "role":
      "user"}, {"content": "Remember, ONLY respond with the task list in the correct
      format! E.g.:\nidx. tool(arg_name=args)", "role": "system"}], "model": "gpt-4-turbo-preview",
      "n": 1, "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '3925'
      content-type:
      - application/json
      cookie:
      - __cf_bm=DxvKOcipR504YFIyOHWGMeMx9MY70WMcWGVSKy_wMmc-1726769508-1.0.1.1-LEjvtkNS0MATEtE3CPM00d9GzfdolnYEIjr2eKQNfp5xad3zOeHBwSkJheM8af6O8gfw8FSCoaLzfelV4Qd70g;
        _cfuvid=_YrqhyvdHQEYp8rjPEpqxVrE9zfcrbwD6yOMNtxZPiI-1726769508416-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"1"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tav"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"ily"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_search"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_results"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_json"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"(query"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"=\""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"current"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        temperature"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        in"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Tokyo"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\")\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"2"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        join"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"()<"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"END"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_OF"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_PLAN"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":">"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-A9Fw4IKwgXwcHjI3MU7WHBDEAAy9H","object":"chat.completion.chunk","created":1726769572,"model":"gpt-4-0125-preview","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b8be1c8e25c17-SJC
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream; charset=utf-8
      Date:
      - Thu, 19 Sep 2024 18:12:52 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '377'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '2000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '1999061'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 28ms
      x-request-id:
      - req_9e3a245d868e97754bab3008c11c9f4a
    status:
      code: 200
      message: OK
- request:
    body: '{"api_key": "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", "query": "current
      temperature in Tokyo", "max_results": 1, "search_depth": "advanced", "include_domains":
      [], "exclude_domains": [], "include_answer": false, "include_raw_content": false,
      "include_images": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '265'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.32.3
    method: POST
    uri: https://api.tavily.com/search
  response:
    body:
      string: "{\"query\":\"current temperature in Tokyo\",\"follow_up_questions\":null,\"answer\":null,\"images\":[],\"results\":[{\"title\":\"Tokyo,
        Japan 14 day weather forecast - timeanddate.com\",\"url\":\"https://www.timeanddate.com/weather/japan/tokyo/ext\",\"content\":\"Tokyo
        14 Day Extended Forecast. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past
        Weather Climate (Averages) Currently: 88 \xB0F. Passing clouds. (Weather station:
        Tokyo Heliport, Japan). See more current weather.\",\"score\":0.9948404,\"raw_content\":null}],\"response_time\":1.76}"
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '524'
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:12:56 GMT
      Server:
      - nginx
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "Solve a question answering task. Here are some
      guidelines:\n - In the Assistant Scratchpad, you will be given results of a
      plan you have executed to answer the user''s question.\n - Thought needs to
      reason about the question based on the Observations in 1-2 sentences.\n - Ignore
      irrelevant action results.\n - If the required information is present, give
      a concise but complete and helpful answer to the user''s question.\n - If you
      are unable to give a satisfactory finishing answer, replan to get the required
      information. Respond in the following format:\n\nThought: <reason about the
      task results and whether you have sufficient information to answer the question>\nAction:
      <action to take>\nAvailable actions:\n (1) Finish(the final answer to return
      to the user): returns the answer and finishes the task.\n (2) Replan(the reasoning
      and other information that will help you plan again. Can be a line of any length):
      instructs why we must replan", "role": "system"}, {"content": "Find the current
      temperature in Tokyo, then, respond with a flashcard summarizing this information",
      "role": "user"}, {"content": "[{''url'': ''https://www.timeanddate.com/weather/japan/tokyo/ext'',
      ''content'': ''Tokyo 14 Day Extended Forecast. Weather Today Weather Hourly
      14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 88 \u00b0F.
      Passing clouds. (Weather station: Tokyo Heliport, Japan). See more current weather.''}]",
      "name": "tavily_search_results_json", "role": "function"}, {"content": "join",
      "name": "join", "role": "function"}, {"content": "Using the above previous actions,
      decide whether to replan or finish. If all the required information is present.
      You may finish. If you have made many attempts to find the information without
      success, admit so and respond with whatever information you have gathered so
      the user can work well with you.\n\n", "role": "system"}], "model": "gpt-4-turbo-preview",
      "n": 1, "parallel_tool_calls": false, "stream": false, "temperature": 0.7, "tool_choice":
      {"type": "function", "function": {"name": "JoinOutputs"}}, "tools": [{"type":
      "function", "function": {"name": "JoinOutputs", "description": "Decide whether
      to replan or whether you can return the final response.", "parameters": {"properties":
      {"thought": {"description": "The chain of thought reasoning for the selected
      action", "type": "string"}, "action": {"anyOf": [{"description": "The final
      response/answer.", "properties": {"response": {"title": "Response", "type":
      "string"}}, "required": ["response"], "title": "FinalResponse", "type": "object"},
      {"properties": {"feedback": {"description": "Analysis of the previous attempts
      and recommendations on what needs to be fixed.", "title": "Feedback", "type":
      "string"}}, "required": ["feedback"], "title": "Replan", "type": "object"}]}},
      "required": ["thought", "action"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2876'
      content-type:
      - application/json
      cookie:
      - __cf_bm=Uu4bOpcl2zXOpJFJ_STXy4gT_7wIFt5lF8hF4YWkY6c-1726769526-1.0.1.1-Rxh4OcmTuy0JRlwTcCMv24cdGOi6xdzpe0pUfno_AJS8Rv17SPmSfYtP23E7oi4ZgdC9HSM3qzV60mI9nlw2JA;
        _cfuvid=Ief420O76508IGoTYURc5WT.FJYfyPR00a7._6etZFE-1726769526641-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//fFPbattAEH33Vwz7KOzgXHzTW3EJSUmaQk2hVMVsViNpk711dzaua/xP
        /YZ+WVlZsZ2QVg9CzNlz2dHMpgfAZMlyYKLhJLRTg3ezy9XsdrX4ejXWcf7weBNufkxvv9yffb7x
        E9ZPDHv/gIKeWSfCaqeQpDU7WHjkhEn1dHI2noxno8mkBbQtUSVa7WhwMRieno0GzuOTxFXHbKwU
        GFgO33oAAJv2nTKaEn+yHIb954rGEHiNLN8fAmDeqlRhPAQZiBti/QMorCE0KbaJSh0BZK1aCq7U
        wXj3bI6+D43iSi3H8/XpuhnyW7u6W4+n13oSlRldnx/57aTXrg1URSP2DTrC9/X8lRkAM1y33A9W
        mrtILlJ4RQdg3NdRo6EUnW0KRo2NdUMFywu2aBBE9B4NAaF26DlFjyANLOzj2oIM4Lx9kiWWqUgN
        QkDuRQMeQ1TUh1UjRZPOTafw5/flCSwaGUCaynrNU/CEhVhVUsjWxsLu7wOHSvHQCO5LCFFr7uUv
        aerW5H+hTgrWLxhvu1KwfFMwj8FZE7C9U5ZdPsvmMO90Fm/oZFlRmKIwA8iyIzzPsu4uHTa3ppTJ
        LCGf0uCYGoSysQzdiY+WWtp7Thwqb3XXvStU0llPsEJODXoI1LbkpGDbLXvxo7a9t76/H82gxyoG
        rrrh7Orb/bQrWztv78Or4WWVNDI0S488tEPEAlm3804+rQOLLxaFOW+1oyXZRzRJ8GJ2vtNjh0U+
        oNNRB5Ilrg710WT6L9ayROKy3ab9Au8SSlMfFIb7mO09WVgHQr2spKnROy/3q9rb9v4CAAD//wMA
        cG7N66kEAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b8bffddc89429-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:13:00 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '3453'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '2000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '1999568'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 12ms
      x-request-id:
      - req_c004be8e2875bcf53e46868aa5c74c5e
    status:
      code: 200
      message: OK
version: 1
