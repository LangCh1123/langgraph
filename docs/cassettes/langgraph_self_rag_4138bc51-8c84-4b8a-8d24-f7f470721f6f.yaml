interactions:
- request:
    body: '{"input": [[849, 21435, 1268, 8957, 315, 3463, 50745, 4375, 30]], "model":
      "text-embedding-ada-002", "encoding_format": "base64"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '129'
      content-type:
      - application/json
      cookie:
      - __cf_bm=AcqgQy88m6qQBZQpQoyFbakoHggOYId_8TqvXuUOik4-1726769424-1.0.1.1-BW3akkkq4bix5eAVx13c7696IK3B2.foZBdHKeRQ3eZs9ZuPpWWA1SClwsCGM9fHjggz95aVqyhgoRAXcNlaZg;
        _cfuvid=idRaWHwwVdP76BKl2Q1fBP_R.loYPhdAl6aZkRqLIfY-1726769424672-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/embeddings
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1R6XQ+ySrPl/fsrdvat80ZEoIt9x5d8QyMo6mQyAUUUROSjG+iT898n+pycmbkx
        ETsC3VWr1lpV//Gvv/76u82r4jr+/c9ff7+ew/j3//heu2Vj9vc/f/3Pf/31119//cfv8/9bWTR5
        cbs93+Vv+e/H5/tWzH//8xf331f+76J//vrb8HYBNaXDux/082YF/cpk1AzqyJuNg+sDeigiDcWy
        9lgqRZLs3jcxdeLwjIZQECNJjFKeBvXLY1PB7rEEOd7goJjW+oLnepAM0+LDWr1VjJR0MMHJwmco
        5aOcTI3Wr9DBkfbU5AOOjV5QD4Clc05vWxz0wz2UFyS4kYQ9wXAqprhnE7JLwNGdPHv6YiSFiS62
        E2HffJ/7+ba2GumFWoea25tbbfbj7QxhKw2h/Nqo/QatjibsKzaEcmlZbITmrEGHB4/euHOEpruj
        XmWuWll4Vztiz+RmKBCB544q1uaGFrx7hqi47Xms3t9Mn6z+koIX1A9srhGpZuy7HXo6qo+VWCqT
        2Y5bV2xPk4I9kw/YxDlNBuYu5cgM6KSzRKUHqF91SK+qMvdkZa4GcMu4oKrNFz11lZ4HxodCuK2D
        ZzJ5Iy8A3uQGNfIjYwM51YJsjp8S22mtIM4DWwFr2HI4mB8MjUy+NACLdSOTe3SqmX0ONnoc4wFj
        +axWW61/8hB5m5Jw5f6qz2GRnyV83inUjc7QDwLJSsmZDZceVkqZjzPnCSgo4pq6sdDqn7t9S8FF
        ZI/9l3Hvl9em0iA2dxbGu+TjzdjXOshvXId319s76ZAbXBGVvYIgjSKPuo2kwez0PHbPjaYvgrKe
        kP/aPUMxInXFYjwVEJMLI6+TMOXL425rMBefgO6qQ60vPXqAtNuNR7JYYlPNjukRdAJDx1c+HPXe
        v7oRcBVYNDdMndHqBQK8NCH+vt+1muLNsxRfwZ2SqRh3yaYanStKIorxjlofvWWpy4u62Nk4pP0p
        Z4fT/oq4aauQ1X2+V7N9vl5BGOojNSqpq4gfjjHY7ztQ27NHfVG7Zwx+GEghfONzMTVJgdOdidjg
        kcyWbXDwIRwlPfzuvzfxMZjQM8PDqXU30OYjcAPIfXynOzUk/eD4gw2R2NDwjY62N+VFu0K8d7eo
        9qkRomJrlvBY6gmbIbdD2wz4QlaJnGKlFfWcXx6Wgk6XpQ1YY53zOeErAzrfEam3ldOKhfv4uXYG
        c6Feqd/1xUDRStY+74J86vVYzYHGrUA4OSzkXq3Rb+QLqqFXTi/sVlqRsJeFB5QwrSPr5N6g4XzM
        Y8hNWad694KcrUlwRUa68rEty5iNQw6hlPGVQN23s/febzhJULr4QlYTCpIJrVUfhKvjYme/taqN
        bZwUFFySINSd/bliL6o1UtcqAk7f1YJG7uRl8HSKEzZPn9ybLjRQwGq4ih4D9soXW3B9MKTkQZ1b
        5/f90L4MgLI7Y/19Cr0ZBv+A2tOiYPum3JL5GDsN6rkqoq4nnZNFOGx8EA1Rw+G1MxI++7xsSQZa
        E1726p5c3S384gv/zmuOc6MVj0IkUv2za/V5c55MOZjsDbUif8sGtHZC4M6WjW2ff+tzoUAK17Fw
        aBiekr7rXlseYVGOwu37IFfziR1S5PZ7E1vKZUHs6XsuHJybSX/xTvNVb//2D2tOOaKFCnkIqNEi
        ujsJUTJlNs9JNDwfw0l5UzSFnmvCvmU6EdNjX82iHtXA6dZM0GWVsLm6+JokvsMbtYJjxpa1XWWw
        TLWNg/NiMm5iegrsxUZqtX2TDCXUIKsVELrbq6xinxN/Bl/HMWkuSsUms5pS+ebjmPqX85gsjVOW
        sB+XDGNrUNG2uc4cOIOxkNOobashr28xsBk/8BePKhaeQg5NfPqgOMZ7bxKuzgRpo9jU8aOyZ2h3
        GQDyYEPN8miwYWJeKm02Wo+teKiSj38MBkl8YpNqEaj9hnhnF8Us98I5DN762DXVCvIb3xE+nwK0
        Za5bAi+GKbW3gtGPm+XBgTmEOQ0ehCAmx2/ll58YtyHnffQmBlij6kS9OFYrtg+9BdLlzoebz4Um
        0/lzJqipMxX76SNKlsc2MJC/eY7h1lQu7J3BqkBhhY5UVxhXDTM3afKEVULdUzroy618mkD0JcS2
        fa68Mc79DsixLbDqpa43mO/1Smo3poGD+tWjitw2BzjpBx/nr8yqaIyFKyRutGBnrut8Sv2ghmjH
        Y+yt41O1eWxnH5Dr7Kn9CjU0T1lsw0u7W3h3k/OKFZvSgHDDvvmOnmzRxTqSxlxLv981tASdR8T7
        mJbU7Ltd3zPXfQLo6QG7WfDR21PSNFDdy5gWcFJ18hTEBaQmm6myrEgya0JPkBlKJ7yT514ndeY3
        0uZTb3F42I09exidjfRxdrCptK1Hz1YTwb0RDGy+ffVbL4QC0rtbUiW1SUUOFfGRFWUWVVfewCY+
        5kxIRBXhYD3O/Tw6VQHVsm2xycl3vV4l2wY+ZuWEIO5c773N5hC4j3zGzpQ/kvnQma2cm2udoF4N
        e/arL8X6tf/ig5APp4Q0UIPS0d20qbx5G9oHCKxMxnjcIG/0P5794xNYZcLVW06kbNAQZRgr5cHv
        mdssGsIreNPdN15oK0QxZJ9uTaa1lOaTKt+vaOqkEdsSffSfnvgr+PGLi6EhfRQ3+AxyH93xbq0q
        jPh86aLXJSVUX9MPYhf6saWHwws4uEXdFz90Fyw5XtPd7qgm3M7eCygjbYqDiyN4w55tOPikcKDK
        2/vk7/mtK+g87z+kg/nJpl+8RZPuYyXZz/0UO6WGfvGpLc7S//giGAJ3xfeVcGQf79HZ4quent/8
        e1RTuwUX5MsZh8LBOOafODc6ON5XPg2KUqk2AxU7dFe0G3ns800+upZwhpd2s7C1eYf5rCvGAtXB
        uFN1thd9wE1byiBUIt5VB8MbFoIFdJz5G8WqnybzRwACYnTgafypEWOPaegQ3nd1WAqDnc/bUDmA
        bdhvusv4Up/uoTwBktH85au3ZNKVSQCr4Suq8P61Ysmn84Ea+RsH8uHMJkdoOtDP84LVPHqg0YrQ
        FQZ5iKnpH6SctbFmgLZRY7JCipAQzxYAbn4Qh+tLvejTJ4k7lOrDGE4GeVbzOVw4kLPNAWM+m9ky
        W8foh8/Uiz8xYwYnlKhk2ZU81HZKiIHOgHqPncOZPjq27BsA9OMnSf2uvcEpOEkytx3+4qGe83ge
        BtRI3C1Em8DvJw8UTT7ze4Vsus9LX771DK3PoRbWm9zpWR6XLQQnzg75Jrl5y7XYZNCZbktd68rl
        zB2aVGb0GH33Byr6ygMbFOTzWHO2d+9RupqCvnoDhx3/9KabWhayvUUWmXTF7qfnRbDh4Ah77O0v
        sj60ntgiy3jYOLxnJBmxELjI6fs3mfNIZZzjDy4gbLdUyySRLbGWXGGlv3x8Hiqdtc+zV0CAvBup
        RLzK2TxsUzREZ4z1NXXQLG6sTNpM6gHrczV44+leCKIa7EzqqpsxmTvluIBQaQup1ZvO2GZflfBW
        hx2+uXden9eVGsm/+PrGQz8ZpDTRIx1n6t7ybTLdxieAX3x29Pw8vdCSyc9Gam7PCzW+fI9t9n0p
        XdvrEn7fv+KzIyWoGEeVxsOz75civKTiY2kmqj+mt7e4u1Pzw7dQWFyXMaNkJnzxgwbCvepZgF8c
        ZBfMUaOZrX5JJq0Fqc9sqku2xlo/Jza6XbtbyJibePxmcM6Sp78ZQUuKe15b9BiIw+40DJVnsriX
        m4bmsir+5Hf3rLkDZOXuinUVtlWni0MM3ecuE6k7rZNxjcwU+uNk4WvWVjp1lYqH9dnX8CGyXoym
        /mcA6w7oq68uPZ2SoIHV9jiE8+M4ekt8qEPJ5YmE7c1Z9Kg2311BEBSHxiVt+jGmrgFpEEVf/ZXo
        k4k2Z0BbocQKqnYeu2yOV9hx6PPl5+uKiW34/FNvjEF+9d/8bJE7jxU2yUOrJvui1BBc9gHG1xzr
        i36XSnFJIoPutMLIOSIjAz7rRCHb2XHzmRcKF1av25XqwbnPJ/HBG+D70+and756NDXR4mfXL199
        91NSXRZQrCLFX7zrZ3kUFSiHksNq7Xc6G6JSQVezeWJdr4pq9vA+Q7SMG6qfbmm+lHnTwmHpHOz6
        ap8MavUiyMifZ+pY/acaYTBSOJ9XQHVNd5MpNfeRfOpbIdy84ms1Lg/kwovOLjVD7sUWj2MFfPM/
        3NgV7We+3JvgvLqUKhl+JNTfgAZa4mlYfRaRNxcHcZL21TzQL7/Q/+hv976Nw2k+vZOFZ90ZYSnL
        KVY2O/3LTw+wnmUuRPuL7BEjKQwUIOdGcWivkj/nEa1qM+Q92Ua/80bWfYVCJgiB1/cb9QnpQ5vJ
        8gq6fkmuQYgOx3SHcff20SBu0BPFw4qQjQt2Topwf5Buu4WnzpSryfTFe1imxqbK6Vzny6WaeFmm
        XI+zPqrYxDo7/vFDvLs0XbK052cp69fUoL5+cZNRdTAnjcMtDxdV+6A5m3b1jy+QNd1NaJl6fgIo
        Fouascb9yUdUg9ZhNxZsj21e5Qrxop+S5ZLtqjkg2yuYz2DExp1t2bc+Zyi8XQWMsaohdkfXM+II
        UFzEm1O/VMMtRb/4RUIuISIZe/cXz9Tk5LU3PHfSgMxnK9Cweqge3Yf6AodmdqkK9YuNfRt1AEvZ
        Yk17rvRZcsUGvBJtyQpZnnf/9IyTqqxE2CBm2zN7/izw9WvI9H5m/TJ89qE8pJeSmgdx9qaGkCs8
        H0cRK3feTmb3Lhfw3hQv6iRF2E8bLzHB01/sy4/UnJxIW8MpTDkaBGnisRtDZ7h6LgnpDCOi9XiT
        UEs/D+xUe9bP+SzFkH/i4o+eJvwOhagKWo168Byr0dxcV9Jsh3P4/vkf2SQS+OJRKP38CSjoQTpf
        zhaOxuhQLYWU8OjmLgHVOm7fz5weANoQTw83bTTkzEy9g/TlR0Te2hmaBj4zpAkmmV6bwzH5VDuz
        Ro9yKMkmpWMyHZdkgYkKRjjtu66as+4SAbb6DZl4H/r5ux5u7Lmjpn5evNmqBQG2DwjJ+um0aMSl
        baADFp9US6u2ZxnwV9gpdEVWi1d59W2NCNjNVcPR6WwkjF/HA5RZV4dCMlZovgbnBZYiGqh+i3WP
        Wbc6lb764aufgoTdj6GPnn36ptq1TRCZkpkAJtUVe6/s3S9txyLYnuQ7/hTSM/kUCpeCxegV//jc
        sn3sW4hJzrB++3B585jPC/rWQ2o/o8SbXClPReN5VuhZZ4PehfrmKV1jJaWu0E0edV67VHoadyWU
        l9npuSE8+WA6SCH8NYy9RTWuJjj6ZOLEm2t9sneeK5Wr3Ajh1LFkDFLpLEXxaFM18u7V8tr0Crq1
        5h5//Yh+OnTSJHWm3WLlvO6r5ZT1NiyHZEX9Ys0lzFUqDuym0MjG2Hk92y58DF8/IRS5Je7ZZz3H
        8tWsn9i3tiSZBbWXYHjG93Brb3k2JXtHgUO/PL5+w5hPfCM+0RJsH0TAzV6f4k1XwvKyD1S9hVIy
        +frDlHen9wuHjkgrlvqP4ZffIRoFrx9BcbgfvlLsP05JSy+XRhwHqQn5fBpZL5SvJ/A0eFO1gYPO
        HY26hupg3vEPf7ZmqqdAy6ihdnss8lGXzhlyL2eeqo9j4G164gNcMr0koiC+8rnE/AGOj0uMrScv
        9l1tYhfaa+qHz8ucovElFQtsTQuH/EGc9QmK9wHtWmWi+D1RNHsoEWQoJitcVcKSTIFzy9DkaLdw
        cd5KNQUVdhH2Pz796RfK7BsP5xsk1LwVbzbAUi8SeZgx2d7XULXPi+CiEofTf63/1m/0fT5q5Fez
        Gn7+1oDX+h8/cC5dTQNkuAqpI+uFBnrZN+gbL2TW5iSZzcrw0U9/6YfRT+br68bD6qCdSM7ftGQx
        3vkTVPWTYOuQdH2Nm/aJrtJJC1e75cqWW5NmqHqtKDZW0QrNuhRlsm/NBXY+ppJv0XwIIa8Ti4B4
        RcmIS8VEVyKGRHQuekVHLZUglBYgYoOrnEVZ6UNw4u1wDfebN1mnXBLF4yEIhWMPCbEifPjjh9ue
        HXjopSYZbOp3id0TFvPplJAa5HmAcPvzU3YESmjFLqJeU7k94dJ79Eev+PYx7vmD93DhKh01gtbx
        qae+7fNoQc1EmG0fK1ZYgoDkYJWHaNcIXrcZ1LOciDoK19vqgNj9XQCaiz6gnrzo+cRSjZMOS+vQ
        43ux9XGX9yFabU/Dt55b+aJOaS2tApcSaQelTi6VwMN1870z9mkyt3cXgOdaF6dm+mBzNToFnA/Z
        hP2D5CQsOQ4LmgzVpM5cGzmdgkuExKXdU6y/sE53cHmiKN7L2NenvGLd2JaSIe0fgTBJR325+XUH
        j3y0aaj1ajKh3ltA2LvPcHNODz3J+wsP+z26hi/2GvUPk/c1FNJb+ultfd5KGi/B1uDIal1A/oqS
        qgNhaI4EAhArllXGAGq1IuH2xX1yhtfOgDoR2WTFOaia4oB2QMZqHa7pLkIz2fsFNJrZkGVe1GTb
        B2GH5Gx7oBZ3EipiXvsFdqyoqc6rk97ZL/EK5GHE2HRHpi/vvVr+/FKsh62qs8stOqPdqFhU05cE
        kTiNBHi8bcAhW1x9nIanAKvApti8KDrjOtWR0FVxTeoG+4fXcavYhjg3CnycV6b3xSNDLsXLSPWF
        PdDoskWC1kQd/uoFnfclukismw26e3qqPh9PsvTHDzSE2OylBt1TCD7kTFY6ZyTL/Sgd4HgoL6Gw
        nfc/vVJD2J1mEq0lPpmzbh/DN77IIoQym5gumUDCicf4Usce8x3x+euPhPO3f7FceKeGVmwjwsHU
        9WyA5xMNKdfTL//K6ebVAtCGatT7+vNsTA8HsHslpOGFvRMm2G0BAnffhmR5HvLl2x8Ron2sUwVV
        L+9X7yE6DXecUDAQ99O3P3/QK3ZmtQSpGf/89nCVQpfPXdOvIJdoFa5mrfTI1K8WtObX3hePOX1c
        bTINYNndqHk5bfQ5ppqJDvkxJdnbmXWyPLCGMutYh794mCNR5OF61t9hn1s8e8l3KoAMY421eFf3
        817NJClUagXvXfOQ16dgieB7HtiF+YnYOa8Gebe6+9/zU9H05fc/vUSDYrrrw3FJJpSfsjCkpci8
        +bnOfNCJfyB8q271uflIBH311J9+BlP4uAZr2HBUIaWbT/XjYgPSyYbqjSUktLG5DE5TG/3+3/s+
        PwdDnm2JfF4a9tVPBXSqs6fuke48nltlNnzxhapthfJfvqJba+yxdyaF/vU/QiiewwUrX/6yRfM1
        hOa8Cr5+IeonY6EETferSKYv36C3uwxofegnqgWrPZrKlpZSi3ZH6rrJPmdfPYi+/T2sDNa+IgK2
        BTg1/YMscIwqTlv7LvCng4mVR/1Mlh8eTI5yw8b+LemTtG1DEOVOJB3KMv3Pfm33Dx0HKFUS/hmt
        JMk23DcN/GDypnehZfKPj5F7RnLS+ab5R2+FEwpyulLSSIrEmmLLtYZqfLzKAh7y+/zlA1nODrfd
        hEojtEcYHM2b9kzmhEtX9FTd0Uofx+rog64Ie6xd5pQNLHU56MdPS5juB/mweioDCDtCsE30s7f4
        0nuBluvEUJ4fjH3jc0L1ZcTh2tCTfNlLyxn93t/eqG82dJcQkMG2OyJmDFfjr56e9fWLvMTE0vlZ
        LQFidvGoOdOJDaTv0u1Xn5KTUe56umovLlJvzz31P96SLF//CDqXcOEI8rv/4SFa3bU1dr78ccrr
        W/TzW8K1TBfW9kQ0kaJd13Tnd89fPVfQt5/365eyrx90QPL9UpJL+XD65Yt3qBsVjPGJF7xRl6Kz
        /NjWFjXwR+05mbsUEPCvPXb37ZIQy02UP/m1unZ1Pq7Y6wDo+N5hf7GkZMa1RSAM9BHvTmtdJ18+
        gK6bY0+gOWzyBV6VBH7/WFHtutf6WcxvHYIIByEnfLZozgzdkLuqGLCdjBUbV3kZoS+e/OFvH/UW
        ROJEJYOG+P3JGd2+TfAse4fvL+WFlr1Cpj/1245vxOuHqFXgZElniq3hwZgS+WdY0atLtif3nSyW
        m2vb9oN32OdWp6Q+aGsJNqQJqfr1Nxtpyv/Uq/DKTpO3WJF1QOY7MHAAstUzfp2RXz5Q58tP2Iu6
        Dfr2e0nzgJ7NmeEZv/0g4tcPnnzaNyhDFf7Wp8ibBNs4QBV+IGwvC/ZYEYwh/P2bCvjPf/311//6
        TRg07a14fQcDxmIe//3fowL/zm7ZvzmO/zOGQIasLP7+578mEP7+9G3zGf/32NbFe/j7n7/kP6MG
        f4/tmL3+n8v/+t7oP//1fwAAAP//AwAjwSHj3iAAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b887fdae6239d-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:33 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-allow-origin:
      - '*'
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - text-embedding-ada-002
      openai-organization:
      - langchain
      openai-processing-ms:
      - '20'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '10000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '9999991'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_f59676292db04ab7d57d2ad21ad36ebd
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "You are a grader assessing relevance of a retrieved
      document to a user question. \n \n        It does not need to be a stringent
      test. The goal is to filter out erroneous retrievals. \n\n        If the document
      contains keyword(s) or semantic meaning related to the user question, grade
      it as relevant. \n\n        Give a binary score ''yes'' or ''no'' score to indicate
      whether the document is relevant to the question.", "role": "system"}, {"content":
      "Retrieved document: \n\n [8] Wang et al. \u201cSelf-Consistency Improves Chain
      of Thought Reasoning in Language Models.\u201d ICLR 2023.\n[9] Diao et al. \u201cActive
      Prompting with Chain-of-Thought for Large Language Models.\u201d arXiv preprint
      arXiv:2302.12246 (2023).\n[10] Zelikman et al. \u201cSTaR: Bootstrapping Reasoning
      With Reasoning.\u201d arXiv preprint arXiv:2203.14465 (2022).\n[11] Ye & Durrett.
      \u201cThe unreliability of explanations in few-shot in-context learning.\u201d
      arXiv preprint arXiv:2205.03401 (2022).\n[12] Trivedi et al. \u201cInterleaving
      retrieval with chain-of-thought reasoning for knowledge-intensive multi-step
      questions.\u201d arXiv preprint arXiv:2212.10509 (2022). \n\n User question:
      Explain how chain of thought prompting works?", "role": "user"}], "model": "gpt-3.5-turbo-0125",
      "n": 1, "parallel_tool_calls": false, "stream": false, "temperature": 0.0, "tool_choice":
      {"type": "function", "function": {"name": "GradeDocuments"}}, "tools": [{"type":
      "function", "function": {"name": "GradeDocuments", "description": "Binary score
      for relevance check on retrieved documents.", "parameters": {"properties": {"binary_score":
      {"description": "Documents are relevant to the question, ''yes'' or ''no''",
      "type": "string"}}, "required": ["binary_score"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1787'
      content-type:
      - application/json
      cookie:
      - __cf_bm=y4F4olkRNNN5Fa64RNjWyGJTPx5ATs0dpbvQBF.K1IU-1726769425-1.0.1.1-dmqTHbW7wephpZYZ_uXwYyA.m11UYjY1ix8Mwyd_e4IU8bB6PMYD9hkpyROjCyyquPDi3cuX60ryQcILpwGPEg;
        _cfuvid=paZ0W87QyD0AlI6lRGDY7FXS0piFpgULfMaXZMkEN88-1726769425994-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RSy27bMBC86yuIPduBHCl2o1vQIDFQpwWKHgLUhUBRK5ktxRXIFRLH8L8XekRS
        jJYHgtjhzCyHewqEAJ1DIkAdJKuqNsu72weu47fvn79kr/d6e1c+PWdf8Rm3cRE/waJlUPYbFb+z
        rhRVtUHWZHtYOZSMrepqc73erG/jKOqAinI0La2seRld3Sy5cRktw9X1zcA8kFboIRE/AyGEOHV7
        26PN8RUSES7eKxV6L0uEZLwkBDgybQWk99qztAyLCVRkGW3btm2MmQFMZFIljZmM+3WanaegpDEp
        bVe7l3D3lu++2ZcfbCN8eFwbzmZ+vfSx7hoqGqvGgGb4WE8uzIQAK6uO++hkjvekmgot+wsFIUC6
        coASAac9ZNpKd0y9Iod7SPZwRL+HM3zgnYN/nX/NUnFYNF6aIa6hfh7zN1TWjjJ/EScU2mp/SB1K
        3z0LPFPde7c+nQM0H74OakdVzSnTH7StYLSJez2YRmtC1wPGxNLMSJ/C/5HSHFnq7nvHieob1Lac
        FMKxy+6Z4I+esUoLbUt0tdPj7ATn4C8AAAD//wMAlP1wgjoDAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b8881dbbf1742-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:34 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '195'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49999696'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_65a56e281c27edea0b2dd6c0da0aa385
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "You are a grader assessing relevance of a retrieved
      document to a user question. \n \n        It does not need to be a stringent
      test. The goal is to filter out erroneous retrievals. \n\n        If the document
      contains keyword(s) or semantic meaning related to the user question, grade
      it as relevant. \n\n        Give a binary score ''yes'' or ''no'' score to indicate
      whether the document is relevant to the question.", "role": "system"}, {"content":
      "Retrieved document: \n\n Few-shot CoT. It is to prompt the model with a few
      demonstrations, each containing manually written (or model-generated) high-quality
      reasoning chains. \n\n User question: Explain how chain of thought prompting
      works?", "role": "user"}], "model": "gpt-3.5-turbo-0125", "n": 1, "parallel_tool_calls":
      false, "stream": false, "temperature": 0.0, "tool_choice": {"type": "function",
      "function": {"name": "GradeDocuments"}}, "tools": [{"type": "function", "function":
      {"name": "GradeDocuments", "description": "Binary score for relevance check
      on retrieved documents.", "parameters": {"properties": {"binary_score": {"description":
      "Documents are relevant to the question, ''yes'' or ''no''", "type": "string"}},
      "required": ["binary_score"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1259'
      content-type:
      - application/json
      cookie:
      - __cf_bm=y4F4olkRNNN5Fa64RNjWyGJTPx5ATs0dpbvQBF.K1IU-1726769425-1.0.1.1-dmqTHbW7wephpZYZ_uXwYyA.m11UYjY1ix8Mwyd_e4IU8bB6PMYD9hkpyROjCyyquPDi3cuX60ryQcILpwGPEg;
        _cfuvid=paZ0W87QyD0AlI6lRGDY7FXS0piFpgULfMaXZMkEN88-1726769425994-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RSXW/TMBR9z6+w7nM7tc3WsrxNoMFAAjGQEFunyHFuUxfHN9g3pVnV/47ysSSr
        wA+WdY/POdfH9xgIATqFSIDaSlZ5YaY317f8e3f3gQ9vvu8fnt3d4T55G2bhzc97v4RJzaBkh4pf
        WBeK8sIga7ItrBxKxlp1vlosV8vry/CyAXJK0dS0rOBpeHE15dIlNJ3NF1cdc0taoYdIPAZCCHFs
        9rpHm+IBIjGbvFRy9F5mCFF/SQhwZOoKSO+1Z2kZJgOoyDLaum1bGjMCmMjEShozGLfrODoPQUlj
        4jLZJQ+fq08m3CuqbrMv/PXb/uOfHyO/VroqmoY2pVV9QCO8r0dnZkKAlXnDfe9kiu9IlTla9mcK
        QoB0WQdFAo5rSLSVroq9IodriNZQoV/DCV7xTsG/zk+jVBxuSi9NF1dXP/X5G8oKR4k/ixM22mq/
        jR1K3zwLPFPRetc+jQOUr74OCkd5wTHTL7S14GK2avVgGK0BXXYYE0szIs3D/5HiFFnq5nv7iWob
        1DYbFGZ9l80zwVeeMY832mboCqf72QlOwV8AAAD//wMA/xkCsDoDAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b8883de301742-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:34 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '156'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49999819'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_6b2348515efe8ebb2674ca01d0d76647
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "You are a grader assessing relevance of a retrieved
      document to a user question. \n \n        It does not need to be a stringent
      test. The goal is to filter out erroneous retrievals. \n\n        If the document
      contains keyword(s) or semantic meaning related to the user question, grade
      it as relevant. \n\n        Give a binary score ''yes'' or ''no'' score to indicate
      whether the document is relevant to the question.", "role": "system"}, {"content":
      "Retrieved document: \n\n [13] Press et al. \u201cMeasuring and narrowing the
      compositionality gap in language models.\u201d arXiv preprint arXiv:2210.03350
      (2022).\n[14] Yao et al. \u201cReAct: Synergizing reasoning and acting in language
      models.\u201d ICLR 2023.\n[15] Fu et al. \u201cComplexity-based prompting for
      multi-step reasoning.\u201d arXiv preprint arXiv:2210.00720 (2022).\n[16] Wang
      et al. \u201cRationale-augmented ensembles in language models.\u201d arXiv preprint
      arXiv:2207.00747 (2022).\n[17] Zhang et al. \u201cAutomatic chain of thought
      prompting in large language models.\u201d arXiv preprint arXiv:2210.03493 (2022).\n[18]
      Shum et al. \u201cAutomatic Prompt Augmentation and Selection with Chain-of-Thought
      from Labeled Data.\u201d arXiv preprint arXiv:2302.12822 (2023). \n\n User question:
      Explain how chain of thought prompting works?", "role": "user"}], "model": "gpt-3.5-turbo-0125",
      "n": 1, "parallel_tool_calls": false, "stream": false, "temperature": 0.0, "tool_choice":
      {"type": "function", "function": {"name": "GradeDocuments"}}, "tools": [{"type":
      "function", "function": {"name": "GradeDocuments", "description": "Binary score
      for relevance check on retrieved documents.", "parameters": {"properties": {"binary_score":
      {"description": "Documents are relevant to the question, ''yes'' or ''no''",
      "type": "string"}}, "required": ["binary_score"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1876'
      content-type:
      - application/json
      cookie:
      - __cf_bm=y4F4olkRNNN5Fa64RNjWyGJTPx5ATs0dpbvQBF.K1IU-1726769425-1.0.1.1-dmqTHbW7wephpZYZ_uXwYyA.m11UYjY1ix8Mwyd_e4IU8bB6PMYD9hkpyROjCyyquPDi3cuX60ryQcILpwGPEg;
        _cfuvid=paZ0W87QyD0AlI6lRGDY7FXS0piFpgULfMaXZMkEN88-1726769425994-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RSTY/aMBC98yusOcMKCAtNbkhs2+2pX6uqLVVknEkwtT2pPZEWIf57lY9Nsqj1
        wbLm+b03fp7LRAjQGSQC1FGysqWZbeO3/Mdu891i97T6Gh+/2A/r0/cHethunp5hWjPocELFL6w7
        RbY0yJpcCyuPkrFWXWyW6806XkWrBrCUoalpRcmz6O5+xpU/0Gy+WN53zCNphQES8XMihBCXZq97
        dBk+QyLm05eKxRBkgZD0l4QAT6augAxBB5aOYTqAihyjq9t2lTEjgIlMqqQxg3G7LqPzEJQ0Jn1c
        LvPT+88f3Zso3upvu9Wp0o8/Fp9Gfq30uWwayiun+oBGeF9PbsyEACdtw33nZYY7UpVFx+FGQQiQ
        vuigRMBlDwftpD+nQZHHPSR7OGPYwxVe8a6Tf51/jVLxmFdBmi6urn7t8zdUlJ4O4SZOyLXT4Zh6
        lKF5FgSmsvWufRoHqF59HZSebMkp0290tWAUR60eDKM1oOsOY2JpxqT4f6Q0Q5a6+d5+otoGtSsG
        hXnfZfNMCOfAaNNcuwJ96XU/O5Pr5C8AAAD//wMAM7fzRjoDAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b8886897c1742-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:35 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '156'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49999675'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_8619b63474915d8e087670aa328d6dc8
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "You are a grader assessing relevance of a retrieved
      document to a user question. \n \n        It does not need to be a stringent
      test. The goal is to filter out erroneous retrievals. \n\n        If the document
      contains keyword(s) or semantic meaning related to the user question, grade
      it as relevant. \n\n        Give a binary score ''yes'' or ''no'' score to indicate
      whether the document is relevant to the question.", "role": "system"}, {"content":
      "Retrieved document: \n\n Self-Ask (Press et al. 2022) is a method to repeatedly
      prompt the model to ask following-up questions to construct the thought process
      iteratively. Follow-up questions can be answered by search engine results. Similarly,
      IRCoT (Interleaving Retrieval CoT; Trivedi et al. 2022) and ReAct (Reason +
      Act; Yao et al. 2023) combines iterative CoT prompting with queries to Wikipedia
      APIs to search for relevant entities and content and then add it back into the
      context.\n\n\n\nFig. 1. How Self-Ask works with external search queries.(Image
      source: Press et al. 2022).\n\nTree of Thoughts (Yao et al. 2023) extends CoT
      by exploring multiple reasoning possibilities at each step. It first decomposes
      the problem into multiple thought steps and generates multiple thoughts per
      step, essentially creating a tree structure. The search process can be BFS or
      DFS while each state is evaluated by a classifier (via a prompt) or majority
      vote. \n\n User question: Explain how chain of thought prompting works?", "role":
      "user"}], "model": "gpt-3.5-turbo-0125", "n": 1, "parallel_tool_calls": false,
      "stream": false, "temperature": 0.0, "tool_choice": {"type": "function", "function":
      {"name": "GradeDocuments"}}, "tools": [{"type": "function", "function": {"name":
      "GradeDocuments", "description": "Binary score for relevance check on retrieved
      documents.", "parameters": {"properties": {"binary_score": {"description": "Documents
      are relevant to the question, ''yes'' or ''no''", "type": "string"}}, "required":
      ["binary_score"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2038'
      content-type:
      - application/json
      cookie:
      - __cf_bm=y4F4olkRNNN5Fa64RNjWyGJTPx5ATs0dpbvQBF.K1IU-1726769425-1.0.1.1-dmqTHbW7wephpZYZ_uXwYyA.m11UYjY1ix8Mwyd_e4IU8bB6PMYD9hkpyROjCyyquPDi3cuX60ryQcILpwGPEg;
        _cfuvid=paZ0W87QyD0AlI6lRGDY7FXS0piFpgULfMaXZMkEN88-1726769425994-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//dFJBbtswELzrFcSe7UCxYyfWLW1aoyjQNkUOBepCoKiVTIfisuSqjWH4
        74UkW1KMlAeC2OHMLId7iIQAnUMiQG0lq8qZ6f3qI/v48a/5wr8/rXm9Wz+/7LB8+PDn6x3BpGFQ
        tkPFZ9aVosoZZE22g5VHydioXt/OlrfL1c180QIV5WgaWul4Or9aTLn2GU3j69nixNySVhggET8j
        IYQ4tHvTo83xBRIRT86VCkOQJULSXxICPJmmAjIEHVhahskAKrKMtmnb1saMACYyqZLGDMbdOozO
        Q1DSmPTx25bc+6f4O934p0y9o+JzWMgf85FfJ713bUNFbVUf0Ajv68mFmRBgZdVy117m+ECqrtBy
        uFAQAqQvT1Ai4LCBTFvp92lQ5HEDyQb2GDZwhFe8Y/TW+dcoFY9FHaQ5xXWqH/v8DZXOUxYu4oRC
        Wx22qUcZ2mdBYHKdd+PTOkD96uvAeaocp0zPaBvB+d2y04NhtAb0jDGxNCPSavY/UpojS91+bz9R
        XYPaloNC3HfZPhPCPjBWaaFtid553c9OdIz+AQAA//8DACnTYQQ6AwAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b88895cb11742-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:35 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '201'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49999626'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_bef2e6040acedcacd5cede35ce1d5d3f
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "You are an assistant for question-answering
      tasks. Use the following pieces of retrieved context to answer the question.
      If you don''t know the answer, just say that you don''t know. Use three sentences
      maximum and keep the answer concise.\nQuestion: Explain how chain of thought
      prompting works? \nContext: [Document(metadata={''description'': ''Prompt Engineering,
      also known as In-Context Prompting, refers to methods for how to communicate
      with LLM to steer its behavior for desired outcomes without updating the model
      weights. It is an empirical science and the effect of prompt engineering methods
      can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis
      post only focuses on prompt engineering for autoregressive language models,
      so nothing with Cloze tests, image generation or multimodality models.'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'',
      ''title'': \"Prompt Engineering | Lil''Log\"}, page_content=''[8] Wang et al.
      \u201cSelf-Consistency Improves Chain of Thought Reasoning in Language Models.\u201d
      ICLR 2023.\\n[9] Diao et al. \u201cActive Prompting with Chain-of-Thought for
      Large Language Models.\u201d arXiv preprint arXiv:2302.12246 (2023).\\n[10]
      Zelikman et al. \u201cSTaR: Bootstrapping Reasoning With Reasoning.\u201d arXiv
      preprint arXiv:2203.14465 (2022).\\n[11] Ye & Durrett. \u201cThe unreliability
      of explanations in few-shot in-context learning.\u201d arXiv preprint arXiv:2205.03401
      (2022).\\n[12] Trivedi et al. \u201cInterleaving retrieval with chain-of-thought
      reasoning for knowledge-intensive multi-step questions.\u201d arXiv preprint
      arXiv:2212.10509 (2022).''), Document(metadata={''description'': ''Prompt Engineering,
      also known as In-Context Prompting, refers to methods for how to communicate
      with LLM to steer its behavior for desired outcomes without updating the model
      weights. It is an empirical science and the effect of prompt engineering methods
      can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis
      post only focuses on prompt engineering for autoregressive language models,
      so nothing with Cloze tests, image generation or multimodality models.'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'',
      ''title'': \"Prompt Engineering | Lil''Log\"}, page_content=''Few-shot CoT.
      It is to prompt the model with a few demonstrations, each containing manually
      written (or model-generated) high-quality reasoning chains.''), Document(metadata={''description'':
      ''Prompt Engineering, also known as In-Context Prompting, refers to methods
      for how to communicate with LLM to steer its behavior for desired outcomes without
      updating the model weights. It is an empirical science and the effect of prompt
      engineering methods can vary a lot among models, thus requiring heavy experimentation
      and heuristics.\\nThis post only focuses on prompt engineering for autoregressive
      language models, so nothing with Cloze tests, image generation or multimodality
      models.'', ''language'': ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'',
      ''title'': \"Prompt Engineering | Lil''Log\"}, page_content=''[13] Press et
      al. \u201cMeasuring and narrowing the compositionality gap in language models.\u201d
      arXiv preprint arXiv:2210.03350 (2022).\\n[14] Yao et al. \u201cReAct: Synergizing
      reasoning and acting in language models.\u201d ICLR 2023.\\n[15] Fu et al. \u201cComplexity-based
      prompting for multi-step reasoning.\u201d arXiv preprint arXiv:2210.00720 (2022).\\n[16]
      Wang et al. \u201cRationale-augmented ensembles in language models.\u201d arXiv
      preprint arXiv:2207.00747 (2022).\\n[17] Zhang et al. \u201cAutomatic chain
      of thought prompting in large language models.\u201d arXiv preprint arXiv:2210.03493
      (2022).\\n[18] Shum et al. \u201cAutomatic Prompt Augmentation and Selection
      with Chain-of-Thought from Labeled Data.\u201d arXiv preprint arXiv:2302.12822
      (2023).''), Document(metadata={''description'': ''Prompt Engineering, also known
      as In-Context Prompting, refers to methods for how to communicate with LLM to
      steer its behavior for desired outcomes without updating the model weights.
      It is an empirical science and the effect of prompt engineering methods can
      vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis
      post only focuses on prompt engineering for autoregressive language models,
      so nothing with Cloze tests, image generation or multimodality models.'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'',
      ''title'': \"Prompt Engineering | Lil''Log\"}, page_content=''Self-Ask (Press
      et al. 2022) is a method to repeatedly prompt the model to ask following-up
      questions to construct the thought process iteratively. Follow-up questions
      can be answered by search engine results. Similarly, IRCoT (Interleaving Retrieval
      CoT; Trivedi et al. 2022) and ReAct (Reason + Act; Yao et al. 2023) combines
      iterative CoT prompting with queries to Wikipedia APIs to search for relevant
      entities and content and then add it back into the context.\\n\\n\\n\\nFig.
      1. How Self-Ask works with external search queries.(Image source: Press et al.
      2022).\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple
      reasoning possibilities at each step. It first decomposes the problem into multiple
      thought steps and generates multiple thoughts per step, essentially creating
      a tree structure. The search process can be BFS or DFS while each state is evaluated
      by a classifier (via a prompt) or majority vote.'')] \nAnswer:", "role": "user"}],
      "model": "gpt-3.5-turbo", "n": 1, "stream": false, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '5733'
      content-type:
      - application/json
      cookie:
      - __cf_bm=l7rKcrdvxr_7_gxPLgm50Q4rhk7Lispv9K6TAdrJ5xc-1726769427-1.0.1.1-X8EImlury1hYTnL8T_cBthrLbnX6VqrVQ4oSaUNP.q57d20UYuAcxHi25sSasVzKh3hU3d8isOkkrS.7f4g.SQ;
        _cfuvid=gBwrASghz9d65cAyT_D2nsp.BdpR_893Jjr_ir_gnuc-1726769427297-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//dFI7bxsxDN79KwgtXWzDz6TxZgQw0K1Dh6ZFYeh0vJManaiIPD8a+L8X
        kh3bHbpoIPU9SH7vAwDlarUCZawW00U/Wj9tJG3iy/Nx9mcTK7ObL9Yvx6/Lxff1j4MaZgRVv9HI
        B2psqIsexVE4t01CLZhZp4+zh8eHp8V8WRod1egzrI0ymo+XI+lTRaPJdLa8IC05g6xW8HMAAPBe
        3uwx1HhQK5gMPyodMusW1er6CUAl8rmiNLNj0UHU8NY0FARDsf1stQtADYilvrUCMVEXxYUW9pRe
        GaojtL2rc8Hr0Pa6RSjuGcSmjAENjMkhZ5qEmink3ywYGfYuEwv0sdaFVewFD3t0rRUewxcBF3bk
        d8hZfndWq7GjwJJ0XicDJbCutaO3Xnsnxzshk0dgELp4v5PApkEjbof+OIZv1jF0KJZqMDpAhYDB
        6mCwzlMa6ipXCJ1gVt3h/TKcWMCDYAraA6NOxsJbf55bCDAkZ2yRLts9COhQg+vyQHiz9IkhYmoo
        dVl4fH+VhE3POqci9N5f6qfrmT21MVHFl/613rjg2G7P+8gnZaGoSvc0APhV4tT/kxB1nmsr9Ioh
        E07ns+mZUN0ifGs/XMKmhET7e9jn/8K2NYp2nu9iqa43u1FMrkbLpIqPLNhtGxdaTDG5ktKyj9Pg
        LwAAAP//AwCaq5TzpAMAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b888c19556456-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:36 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '757'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998602'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_8c2ba2d18b1e68626ab30e4e28bf06e1
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "You are a grader assessing whether an LLM generation
      is grounded in / supported by a set of retrieved facts. \n \n         Give a
      binary score ''yes'' or ''no''. ''Yes'' means that the answer is grounded in
      / supported by the set of facts.", "role": "system"}, {"content": "Set of facts:
      \n\n [Document(metadata={''description'': ''Prompt Engineering, also known as
      In-Context Prompting, refers to methods for how to communicate with LLM to steer
      its behavior for desired outcomes without updating the model weights. It is
      an empirical science and the effect of prompt engineering methods can vary a
      lot among models, thus requiring heavy experimentation and heuristics.\\nThis
      post only focuses on prompt engineering for autoregressive language models,
      so nothing with Cloze tests, image generation or multimodality models.'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'',
      ''title'': \"Prompt Engineering | Lil''Log\"}, page_content=''[8] Wang et al.
      \u201cSelf-Consistency Improves Chain of Thought Reasoning in Language Models.\u201d
      ICLR 2023.\\n[9] Diao et al. \u201cActive Prompting with Chain-of-Thought for
      Large Language Models.\u201d arXiv preprint arXiv:2302.12246 (2023).\\n[10]
      Zelikman et al. \u201cSTaR: Bootstrapping Reasoning With Reasoning.\u201d arXiv
      preprint arXiv:2203.14465 (2022).\\n[11] Ye & Durrett. \u201cThe unreliability
      of explanations in few-shot in-context learning.\u201d arXiv preprint arXiv:2205.03401
      (2022).\\n[12] Trivedi et al. \u201cInterleaving retrieval with chain-of-thought
      reasoning for knowledge-intensive multi-step questions.\u201d arXiv preprint
      arXiv:2212.10509 (2022).''), Document(metadata={''description'': ''Prompt Engineering,
      also known as In-Context Prompting, refers to methods for how to communicate
      with LLM to steer its behavior for desired outcomes without updating the model
      weights. It is an empirical science and the effect of prompt engineering methods
      can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis
      post only focuses on prompt engineering for autoregressive language models,
      so nothing with Cloze tests, image generation or multimodality models.'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'',
      ''title'': \"Prompt Engineering | Lil''Log\"}, page_content=''Few-shot CoT.
      It is to prompt the model with a few demonstrations, each containing manually
      written (or model-generated) high-quality reasoning chains.''), Document(metadata={''description'':
      ''Prompt Engineering, also known as In-Context Prompting, refers to methods
      for how to communicate with LLM to steer its behavior for desired outcomes without
      updating the model weights. It is an empirical science and the effect of prompt
      engineering methods can vary a lot among models, thus requiring heavy experimentation
      and heuristics.\\nThis post only focuses on prompt engineering for autoregressive
      language models, so nothing with Cloze tests, image generation or multimodality
      models.'', ''language'': ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'',
      ''title'': \"Prompt Engineering | Lil''Log\"}, page_content=''[13] Press et
      al. \u201cMeasuring and narrowing the compositionality gap in language models.\u201d
      arXiv preprint arXiv:2210.03350 (2022).\\n[14] Yao et al. \u201cReAct: Synergizing
      reasoning and acting in language models.\u201d ICLR 2023.\\n[15] Fu et al. \u201cComplexity-based
      prompting for multi-step reasoning.\u201d arXiv preprint arXiv:2210.00720 (2022).\\n[16]
      Wang et al. \u201cRationale-augmented ensembles in language models.\u201d arXiv
      preprint arXiv:2207.00747 (2022).\\n[17] Zhang et al. \u201cAutomatic chain
      of thought prompting in large language models.\u201d arXiv preprint arXiv:2210.03493
      (2022).\\n[18] Shum et al. \u201cAutomatic Prompt Augmentation and Selection
      with Chain-of-Thought from Labeled Data.\u201d arXiv preprint arXiv:2302.12822
      (2023).''), Document(metadata={''description'': ''Prompt Engineering, also known
      as In-Context Prompting, refers to methods for how to communicate with LLM to
      steer its behavior for desired outcomes without updating the model weights.
      It is an empirical science and the effect of prompt engineering methods can
      vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis
      post only focuses on prompt engineering for autoregressive language models,
      so nothing with Cloze tests, image generation or multimodality models.'', ''language'':
      ''en'', ''source'': ''https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'',
      ''title'': \"Prompt Engineering | Lil''Log\"}, page_content=''Self-Ask (Press
      et al. 2022) is a method to repeatedly prompt the model to ask following-up
      questions to construct the thought process iteratively. Follow-up questions
      can be answered by search engine results. Similarly, IRCoT (Interleaving Retrieval
      CoT; Trivedi et al. 2022) and ReAct (Reason + Act; Yao et al. 2023) combines
      iterative CoT prompting with queries to Wikipedia APIs to search for relevant
      entities and content and then add it back into the context.\\n\\n\\n\\nFig.
      1. How Self-Ask works with external search queries.(Image source: Press et al.
      2022).\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple
      reasoning possibilities at each step. It first decomposes the problem into multiple
      thought steps and generates multiple thoughts per step, essentially creating
      a tree structure. The search process can be BFS or DFS while each state is evaluated
      by a classifier (via a prompt) or majority vote.'')] \n\n LLM generation: Chain
      of thought prompting works by guiding language models through a series of reasoning
      steps without updating the model weights. It involves providing demonstrations
      or high-quality reasoning chains to prompt the model effectively. This method
      can be enhanced by combining iterative prompting with external search queries
      to enrich the context and improve the model''s performance.", "role": "user"}],
      "model": "gpt-3.5-turbo-0125", "n": 1, "parallel_tool_calls": false, "stream":
      false, "temperature": 0.0, "tool_choice": {"type": "function", "function": {"name":
      "GradeHallucinations"}}, "tools": [{"type": "function", "function": {"name":
      "GradeHallucinations", "description": "Binary score for hallucination present
      in generation answer.", "parameters": {"properties": {"binary_score": {"description":
      "Answer is grounded in the facts, ''yes'' or ''no''", "type": "string"}}, "required":
      ["binary_score"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '6564'
      content-type:
      - application/json
      cookie:
      - __cf_bm=gbPqaEJus6B8nD2cBtfP2g2BPwKfHnA9_6FUPIg5zVc-1726769427-1.0.1.1-RalIslv5lLJG0mrroEjFf70jWJLARn.SQmLnyRRhYRxpus.TOY84gseykdUBXDzy.oalPXMIEmMmZIqpcHluvg;
        _cfuvid=NnbdmQNsKGwzUzphwZ0sglAc80q8325mSK67ocIDIyc-1726769427887-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//dFLbauMwEH33V4h5TkqSNg7xW6F0Q8veyELJbhYjy2NHW10cacxuCPn3
        RXZqO6HVgxBzdM6Z2zFiDGQOCQOx4yR0pcb3y0fyzw9Pz/sf39ev5dN6v4rrzWZ//3PxuIRRYNjs
        Dwp6Y90IqyuFJK1pYeGQEwbV6WIWL+Ll3W3cANrmqAKtrGh8ezMfU+0yO55MZ/Mzc2elQA8J+xUx
        xtixuUOOJsd/kLDJ6C2i0XteIiTdJ8bAWRUiwL2XnrghGPWgsIbQhLRNrdQAIGtVKrhSvXF7joN3
        3yiuVJptii842/B1HM/0y+f867dl8Xf18DLwa6UPVZNQURvRNWiAd/HkyowxMFw33E+O57jiStVC
        Gh5++ysZxoC7stZoKJQAxy1k0nB3SL2wDreQbOGAfgsnuOCdovfevwetcVjUnqtzz87xUzcEZcvK
        2cxf9RQKaaTfpQ65b2oDT7ZqvYNP4wD1xfygclZXlJJ9RRMEp3fzaSsI/YL1cHzGyBJXF6zFR6w0
        R+KymXK3WG2K0pS9xKTLsykU/MET6rSQpkRXOdmtUHSK/gMAAP//AwBpC6YAQQMAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b88927951f9fd-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:36 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '194'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998517'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_2aed4cea125bc9736921b90440e8a77f
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "You are a grader assessing whether an answer
      addresses / resolves a question \n \n         Give a binary score ''yes'' or
      ''no''. Yes'' means that the answer resolves the question.", "role": "system"},
      {"content": "User question: \n\n Explain how chain of thought prompting works?
      \n\n LLM generation: Chain of thought prompting works by guiding language models
      through a series of reasoning steps without updating the model weights. It involves
      providing demonstrations or high-quality reasoning chains to prompt the model
      effectively. This method can be enhanced by combining iterative prompting with
      external search queries to enrich the context and improve the model''s performance.",
      "role": "user"}], "model": "gpt-3.5-turbo-0125", "n": 1, "parallel_tool_calls":
      false, "stream": false, "temperature": 0.0, "tool_choice": {"type": "function",
      "function": {"name": "GradeAnswer"}}, "tools": [{"type": "function", "function":
      {"name": "GradeAnswer", "description": "Binary score to assess answer addresses
      question.", "parameters": {"properties": {"binary_score": {"description": "Answer
      addresses the question, ''yes'' or ''no''", "type": "string"}}, "required":
      ["binary_score"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1224'
      content-type:
      - application/json
      cookie:
      - __cf_bm=ECa7dvcyDXepO7wvHulNsULpdgkF2wD3DXG59MFi.3w-1726769428-1.0.1.1-2mwxG8IDaDVoAMgGVh36cvqY5A5qrUuEo1579zLe2YDOCg0xpOVSrJsc8fQ38ruSfz5gwh.IlpzP25V3ljCkcg;
        _cfuvid=jtL93xWrAhunxZ8HDJ_ShgIRss7reGYvNwSzM9w5XT8-1726769428431-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.4
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//dFJda9swFH33rxD3OSlJsySL39KNFVYGZaxlbBlGlm8cdfpCum7qhPz3
        ITu13bDqQYh7dO45OrrHhDGQBaQMxI6T0E6N16svRP5m/+3nr/u72afD04ve/3h8oFuPzzWMIsPm
        TyjolXUlrHYKSVrTwsIjJ4xdp8vrxXKx+jBbNoC2BapIKx2NZ1fzMVU+t+PJ9Hp+Zu6sFBggZb8T
        xhg7Nnv0aAp8gZRNRq8VjSHwEiHtLjEG3qpYAR6CDMQNwagHhTWEJto2lVIDgKxVmeBK9cLtOg7O
        fVBcqaw+kHz+HB7cwZRVeb/k37+u87vJ40CvbV27xtC2MqILaIB39fRCjDEwXDfcW88LXJuwR39B
        Zwy4LyuNhqJ1OG4gl4b7OgvCetxAuoEawwZO8IZ3Sv53/jOIxOO2ClydszrXT134ypbO2zxcZAlb
        aWTYZR55aN4EgaxrtaNOowDVm38D5612lJH9iyY2nH6ct/2gn6seXZwxssTVgLSavkfKCiQum7/t
        xqk1KE3Zd5h0LptnQqgDoc620pTonZfd4CSn5B8AAAD//wMAInuGJzcDAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5b889559b0642c-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 18:10:37 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - langchain
      openai-processing-ms:
      - '221'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49999821'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_70e698367827bf678993b71cbf8aee38
    status:
      code: 200
      message: OK
version: 1
