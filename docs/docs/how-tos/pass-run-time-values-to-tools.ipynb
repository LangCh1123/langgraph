{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53",
   "metadata": {},
   "source": [
    "# How to pass runtime values to tools\n",
    "\n",
    "Sometimes we need to pass values to our tools at runtime. For example, you might want to give tools access to:\n",
    "\n",
    "* graph state\n",
    "* [shared memory](https://langchain-ai.github.io/langgraph/how-tos/memory/shared-state/) persisted between sessions\n",
    "\n",
    "This type of stateful tools is useful when a tool's output is affected by past agent steps (e.g. if you're using a sub-agent as a tool, and want to pass the message history in to the sub-agent), or when a tool's input needs to be validated given context from past agent steps.\n",
    "\n",
    "In this guide we'll demonstrate how to create tools that take agent state or LangGraph Store as input.\n",
    "\n",
    "This is a special case of [passing runtime arguments to tools](https://python.langchain.com/docs/how_to/tool_runtime/), which you can learn about in the LangChain docs.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Prerequisites</p>\n",
    "    <p>\n",
    "        This guide assumes familiarity with the following:\n",
    "        <ul>\n",
    "            <li>\n",
    "                <a href=\"https://langchain-ai.github.io/langgraph/concepts/low_level/#state\">\n",
    "                    State\n",
    "                </a>\n",
    "            </li>\n",
    "            <li>\n",
    "                <a href=\"https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#tool-calling-agent\">\n",
    "                    Tool-calling\n",
    "                </a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </p>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd446a-808f-4394-be92-d45ab818953c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we need to install the packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4ce0ba-7596-4e5f-8bf8-0b0bd6e62833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe11f4-62ed-4dc4-8875-3db21e260d1d",
   "metadata": {},
   "source": [
    "Next, we need to set API keys for OpenAI (the chat model we will use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c903a1cf-2977-4e2d-ad7d-8b3946821d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed46a8-effe-4596-b0e1-a6a29ee16f5c",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a5908ab-7c1f-4832-85ae-511536b89b9f",
   "metadata": {},
   "source": [
    "## Pass graph state to tools\n",
    "\n",
    "Let's first take a look at how to give our tools access to the graph.\n",
    "\n",
    "### Define the tools\n",
    "\n",
    "We'll want our tool to take graph state as an input, but we don't want the model to try to generate this input when calling the tool. We can use the `InjectedState` annotation to mark arguments as required graph state (or some field of graph state. These arguments will not be generated by the model. When using `ToolNode`, graph state will automatically be passed in to the relevant tools and arguments.\n",
    "\n",
    "In this example we'll create a tool that returns Documents and then another tool that actually cites the Documents that justify a claim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e2c8d",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">Using Pydantic with LangChain</p>\n",
    "    <p>\n",
    "        This notebook uses Pydantic v2 <code>BaseModel</code>, which requires <code>langchain-core >= 0.3</code>. Using <code>langchain-core < 0.3</code> will result in errors due to mixing of Pydantic v1 and v2 <code>BaseModels</code>.\n",
    "    </p>\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d36e782-80f4-4334-b7d7-ee4c79864480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        \"FooBar company just raised 1 Billion dollars!\",\n",
    "        metadata={\"source\": \"twitter\"},\n",
    "    ),\n",
    "    Document(\n",
    "        \"FooBar company is now only hiring AI's\", metadata={\"source\": \"twitter\"}\n",
    "    ),\n",
    "    Document(\n",
    "        \"FooBar company was founded in 2019\", metadata={\"source\": \"wikipedia\"}\n",
    "    ),\n",
    "    Document(\n",
    "        \"FooBar company makes friendly robots\", metadata={\"source\": \"wikipedia\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "@tool(parse_docstring=True, response_format=\"content_and_artifact\")\n",
    "def get_context(question: List[str]) -> Tuple[str, List[Document]]:\n",
    "    \"\"\"Get context on the question.\n",
    "\n",
    "    Args:\n",
    "        question: The user question\n",
    "    \"\"\"\n",
    "    # return constant dummy output   \n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs), docs\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True, response_format=\"content_and_artifact\")\n",
    "def cite_context_sources(\n",
    "    claim: str, state: Annotated[dict, InjectedState]\n",
    ") -> Tuple[str, List[Document]]:\n",
    "    \"\"\"Cite which source a claim was based on.\n",
    "\n",
    "    Args:\n",
    "        claim: The claim that was made.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    # We get the potentially cited docs from past ToolMessages in our state.\n",
    "    for msg in state[\"messages\"]:\n",
    "        if isinstance(msg, ToolMessage) and msg.name == \"get_context\":\n",
    "            for doc in msg.artifact:\n",
    "                if isinstance(doc, Document):\n",
    "                    docs.append(doc)\n",
    "                elif isinstance(doc, dict):\n",
    "                    docs.append(Document(**doc))\n",
    "\n",
    "    class Cite(BaseModel):\n",
    "        \"\"\"Return the index(es) of the documents that justify the claim\"\"\"\n",
    "\n",
    "        indexes: List[int]\n",
    "\n",
    "    structured_model = model.with_structured_output(Cite)\n",
    "    system = f\"Which of the following documents best justifies the claim:\\n\\n{claim}\"\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"Document {i}:\\n\" + doc.page_content for i, doc in enumerate(docs)\n",
    "    )\n",
    "    citation = structured_model.invoke([(\"system\", system), (\"human\", context)])\n",
    "    cited_docs = [docs[i] for i in citation.indexes]\n",
    "    sources = \", \".join(doc.metadata[\"source\"] for doc in cited_docs)\n",
    "    return sources, cited_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d0de0-0f3e-4bbe-b0b6-cc0f70b11993",
   "metadata": {},
   "source": [
    "If we look at the input schemas for these tools, we'll see that `state` is still listed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1092929b-c939-4b2a-9f9c-e725b0e34af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Cite which source a claim was based on.',\n",
       " 'properties': {'claim': {'description': 'The claim that was made.',\n",
       "   'title': 'Claim',\n",
       "   'type': 'string'},\n",
       "  'state': {'title': 'State', 'type': 'object'}},\n",
       " 'required': ['claim', 'state'],\n",
       " 'title': 'cite_context_sources',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_context_sources.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e346a26e-e00b-48e5-82c5-c930ea6084a4",
   "metadata": {},
   "source": [
    "But if we look at the tool call schema, which is what is passed to the model for tool-calling, `state` has been removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3912bb51-3107-4335-a659-021c5d89fb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Cite which source a claim was based on.',\n",
       " 'properties': {'claim': {'description': 'The claim that was made.',\n",
       "   'title': 'Claim',\n",
       "   'type': 'string'}},\n",
       " 'required': ['claim'],\n",
       " 'title': 'cite_context_sources',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_context_sources.tool_call_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b9211-93d0-4ad5-aa7a-9c09099c53ff",
   "metadata": {},
   "source": [
    "### Define the graph\n",
    "\n",
    "In this example we will be using a [prebuilt ReAct agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/). We'll first need to define our model and a tool-calling node ([ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be341be4-bdc3-4e78-9bc1-7486da27fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode, create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "tools = [get_context, cite_context_sources]\n",
    "\n",
    "# ToolNode will automatically take care of injecting state into tools\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = create_react_agent(model, tools, checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c3931-3dae-4281-ad4e-4b51305594d4",
   "metadata": {},
   "source": [
    "### Use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71af7a7b-b91c-4061-bbb8-b2d9d8c73870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_stream(stream):\n",
    "    for output in stream:\n",
    "        # stream() yields dictionaries with output keyed by node name\n",
    "        for key, value in output.items():\n",
    "            print(f\"Output from node '{key}':\")\n",
    "            print(\"---\")\n",
    "            for message in value[\"messages\"]:\n",
    "                message.pretty_print()\n",
    "        print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8edb04b9-40b6-46f1-a7a8-4b2d8aba7752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_context (call_DDe4qFkNuWF9FeUcQVDqkuYF)\n",
      " Call ID: call_DDe4qFkNuWF9FeUcQVDqkuYF\n",
      "  Args:\n",
      "    question: ['latest news about FooBar']\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tools':\n",
      "---\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_context\n",
      "\n",
      "FooBar company just raised 1 Billion dollars!\n",
      "\n",
      "FooBar company is now only hiring AI's\n",
      "\n",
      "FooBar company was founded in 2019\n",
      "\n",
      "FooBar company makes friendly robots\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The latest news about FooBar includes:\n",
      "\n",
      "1. FooBar company has just raised 1 billion dollars.\n",
      "2. FooBar company is now only hiring AI's.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(\"what's the latest news about FooBar\")]\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "pretty_print_stream(graph.stream({\"messages\": messages}, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a2128ed-e23f-4f25-a026-0c6590f01a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  cite_context_sources (call_JoXpwqa4Ybq86QbC05ZVGUoY)\n",
      " Call ID: call_JoXpwqa4Ybq86QbC05ZVGUoY\n",
      "  Args:\n",
      "    claim: FooBar company just raised 1 Billion dollars!\n",
      "  cite_context_sources (call_v8zaP5YwjrSHodLjpQnnCwiM)\n",
      " Call ID: call_v8zaP5YwjrSHodLjpQnnCwiM\n",
      "  Args:\n",
      "    claim: FooBar company is now only hiring AI's\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tools':\n",
      "---\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: cite_context_sources\n",
      "\n",
      "twitter\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: cite_context_sources\n",
      "\n",
      "twitter\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The information about FooBar company raising 1 billion dollars and only hiring AI's was sourced from Twitter.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(\"where did you get this information?\")]\n",
    "pretty_print_stream(graph.stream({\"messages\": messages}, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd6d7d-d8a8-48f9-a30d-fba79fb7cb1e",
   "metadata": {},
   "source": [
    "## Pass shared memory (store) to the graph\n",
    "\n",
    "You might also want to give tools access to memory that is shared across multiple conversations or users. We can do it by passing LangGraph [Store](https://langchain-ai.github.io/langgraph/how-tos/memory/shared-state/) to the tools using a different annotation -- `InjectedStore`.\n",
    "\n",
    "Let's modify our example to save the documents in an in-memory store and retrieve them using `get_context` tool. We'll also make the documents accessible based on a user ID, so that some documents are only visible to certain users. The tool will then use the `user_id` provided in the [config](https://langchain-ai.github.io/langgraph/how-tos/pass-config-to-tools/) to retrieve a correct set of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41644e7e-bda2-4c0d-95da-99572554c02d",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <list>\n",
    "        <li>\n",
    "        Support for <code>Store</code> API and <code>InjectedStore</code> used in this notebook was added in LangGraph <code>v0.2.34</code>.\n",
    "        </li>\n",
    "        <li>\n",
    "        <code>InjectedStore</code> annotation requires <code>langchain-core >= 0.3.8</code>\n",
    "        </li>\n",
    "    <list>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aea94e-42be-4be7-bc8c-74ba42dc8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "<div class=\"admonition warning\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "    \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759186ed-5506-4e9a-80c4-0a2405ff58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "doc_store = InMemoryStore()\n",
    "\n",
    "for doc_id, doc in enumerate(docs[:2]):\n",
    "    user_id = \"1\"\n",
    "    namespace = (\"documents\", user_id)\n",
    "    doc_store.put(namespace, doc_id, {\"doc\": doc})\n",
    "\n",
    "\n",
    "for doc_id, doc in enumerate(docs[2:]):\n",
    "    user_id = \"2\"\n",
    "    namespace = (\"documents\", user_id)\n",
    "    doc_store.put(namespace, doc_id, {\"doc\": doc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6e4e4-3256-4d42-aa5f-de337bfa6a97",
   "metadata": {},
   "source": [
    "### Define the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ab7e2b-7df4-41ea-8b20-e2ba950aacb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt import InjectedStore\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True, response_format=\"content_and_artifact\")\n",
    "def get_context(\n",
    "    question: List[str],\n",
    "    config: RunnableConfig,\n",
    "    store: Annotated[BaseStore, InjectedStore()]\n",
    ") -> Tuple[str, List[Document]]:\n",
    "    \"\"\"Get context on the question.\n",
    "\n",
    "    Args:\n",
    "        question: The user question\n",
    "    \"\"\"\n",
    "    # return constant dummy output   \n",
    "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
    "    docs = [item.value[\"doc\"] for item in store.search((\"documents\", user_id))]\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs), docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd29b33-b647-4e11-8942-2d47f129095b",
   "metadata": {},
   "source": [
    "We can also verify that the tool-calling model will ignore `store` arg of `get_context` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07bdc124-06bb-4c25-a18e-700ab7aa6521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Get context on the question.',\n",
       " 'properties': {'question': {'description': 'The user question',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Question',\n",
       "   'type': 'array'}},\n",
       " 'required': ['question'],\n",
       " 'title': 'get_context',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_context.tool_call_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10622c58-db67-476b-81a3-1b964f5b471f",
   "metadata": {},
   "source": [
    "### Define the graph\n",
    "\n",
    "Let's update our ReAct agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c70125-a105-4103-89d2-2e93b401080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_context, cite_context_sources]\n",
    "\n",
    "# ToolNode will automatically take care of injecting Store into tools\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "# NOTE: we need to pass our store to `create_react_agent` to make sure our graph is aware of \n",
    "graph = create_react_agent(model, tools, checkpointer=checkpointer, store=doc_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba8adc-c706-48a6-992f-24c03c4cee46",
   "metadata": {},
   "source": [
    "### Use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155ef73-91fe-459d-a3af-7ed254c19e23",
   "metadata": {},
   "source": [
    "Let's try running our graph with a `\"user_id\"` in the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d683986f-faf4-4724-a13f-bac39ea9bafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_context (call_oaUzgWpNUJrmi9lON6uofCIB)\n",
      " Call ID: call_oaUzgWpNUJrmi9lON6uofCIB\n",
      "  Args:\n",
      "    question: ['latest news about FooBar']\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tools':\n",
      "---\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_context\n",
      "\n",
      "FooBar company just raised 1 Billion dollars!\n",
      "\n",
      "FooBar company is now only hiring AI's\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  cite_context_sources (call_6b0c1zyVBWF6dG60IAL9NLjS)\n",
      " Call ID: call_6b0c1zyVBWF6dG60IAL9NLjS\n",
      "  Args:\n",
      "    claim: FooBar company just raised 1 Billion dollars!\n",
      "  cite_context_sources (call_hby5NYD1rdWW0I7jvdXJIJHE)\n",
      " Call ID: call_hby5NYD1rdWW0I7jvdXJIJHE\n",
      "  Args:\n",
      "    claim: FooBar company is now only hiring AI's\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tools':\n",
      "---\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: cite_context_sources\n",
      "\n",
      "twitter\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: cite_context_sources\n",
      "\n",
      "twitter\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The latest news about FooBar includes:\n",
      "\n",
      "1. FooBar company just raised 1 billion dollars! [Source: Twitter]\n",
      "2. FooBar company is now only hiring AI's. [Source: Twitter]\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(\"what's the latest news about FooBar\")]\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "pretty_print_stream(graph.stream({\"messages\": messages}, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac8ead-a4fa-488f-835d-21872c67ec72",
   "metadata": {},
   "source": [
    "We can see that the tool only retrieved the correct documents for user \"1\" when looking up the information in the store. Let's now try it again for a different user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e3fd1e2-cc19-4023-8ffa-b0fc13da9e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_context (call_VFWTHaqHWH5W22zMUyEKNnLL)\n",
      " Call ID: call_VFWTHaqHWH5W22zMUyEKNnLL\n",
      "  Args:\n",
      "    question: ['latest news about FooBar']\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tools':\n",
      "---\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_context\n",
      "\n",
      "FooBar company was founded in 2019\n",
      "\n",
      "FooBar company makes friendly robots\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "FooBar is a company that was founded in 2019 and specializes in making friendly robots. If you need more specific or recent news, please let me know!\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(\"what's the latest news about FooBar\")]\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"2\"}}\n",
    "pretty_print_stream(graph.stream({\"messages\": messages}, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fd8ec-38e7-4300-88f6-9f8774bba313",
   "metadata": {},
   "source": [
    "We can see that the tool pulled in a different set of documents this time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "langgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
