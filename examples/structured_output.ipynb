{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output\n",
    "\n",
    "The ability of LLMs to respond in structured format is extremely helpful for a variety of use cases such as when we want to call funtions with rigid parameters or update databases with defined schemas just to mention a few.\n",
    "\n",
    "In graphs that pass state variables between nodes there are lots of different ways we can utilize structured outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ToolNode\n",
    "\n",
    "This example takes advantage of many pre-built Langchain functions that make adding an agent to your graph simple. First, we define our tools list and then create a node using the built in `ToolNode` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a structured output we would like to return to our user, or perhaps another piece of our software for later use. In this case we will return weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    \"\"\"Final response to the user\"\"\"\n",
    "\n",
    "    temperature: float = Field(description=\"the temperature\")\n",
    "    wind_speed: float = Field(description=\"the wind speed\")\n",
    "    wind_direction: str = Field(description=\"the direction of the wind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define our model and bind our tools (including the `WeatherResponse`) to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True)\n",
    "model = model.bind_tools(tools+[WeatherResponse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the State class we will use for our graph, as well as the update function for our one member variables called `messages` which will just be a list of all the messages generated by our chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Literal\n",
    "\n",
    "def add_messages(left: list, right: list):\n",
    "    \"\"\"Add-don't-overwrite.\"\"\"\n",
    "    return left + right\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The `add_messages` function within the annotation defines\n",
    "    # *how* updates should be merged into the state.\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the function for our model node, as well as the routing function to determine weather we need to call our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_call_tool(state: AgentState) -> Literal[\"search\", \"__end__\"]:\n",
    "    # Check that we do indeed want to call our search tool\n",
    "    if state['messages'][-1].tool_calls and state['messages'][-1].tool_calls[0]['name'] != \"WeatherResponse\":\n",
    "        return \"search\"\n",
    "    return \"__end__\"\n",
    "\n",
    "def call_model(state: AgentState) -> AgentState:\n",
    "    return {\"messages\":[model.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to define our simple graph and compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"search\", tool_node)\n",
    "graph.set_entry_point(\"agent\")\n",
    "graph.add_conditional_edges(\"agent\",should_call_tool)\n",
    "graph.add_edge(\"search\",\"agent\")\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather in Barcelona?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_kGNgs8J6qnBRQdcfaF5CAm9z)\n",
      " Call ID: call_kGNgs8J6qnBRQdcfaF5CAm9z\n",
      "  Args:\n",
      "    query: weather in Barcelona\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'Barcelona', 'region': 'Catalonia', 'country': 'Spain', 'lat': 41.38, 'lon': 2.18, 'tz_id': 'Europe/Madrid', 'localtime_epoch': 1718076123, 'localtime': '2024-06-11 5:22'}, 'current': {'last_updated_epoch': 1718075700, 'last_updated': '2024-06-11 05:15', 'temp_c': 19.4, 'temp_f': 66.9, 'is_day': 0, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/night/122.png', 'code': 1009}, 'wind_mph': 3.8, 'wind_kph': 6.1, 'wind_degree': 330, 'wind_dir': 'NNW', 'pressure_mb': 1012.0, 'pressure_in': 29.88, 'precip_mm': 0.49, 'precip_in': 0.02, 'humidity': 78, 'cloud': 100, 'feelslike_c': 19.4, 'feelslike_f': 66.9, 'windchill_c': 18.8, 'windchill_f': 65.9, 'heatindex_c': 18.8, 'heatindex_f': 65.9, 'dewpoint_c': 15.3, 'dewpoint_f': 59.6, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 1.0, 'gust_mph': 3.8, 'gust_kph': 6.2}}\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  WeatherResponse (call_PdTi0eB3xe5bR7uxEc64aFia)\n",
      " Call ID: call_PdTi0eB3xe5bR7uxEc64aFia\n",
      "  Args:\n",
      "    temperature: 19.4\n",
      "    wind_speed: 6.1\n",
      "    wind_direction: NNW\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "ans = app.invoke({'messages':[HumanMessage(content=\"What is the weather in Barcelona?\")]})\n",
    "for message in ans['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run our model, we can see that it correctly executed the Tavily search as we expected, and in the last message it correctly returned data in the correct `WeatherResponse` structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Tools Manually\n",
    "\n",
    "Sometime we have structured inputs to tools, but the LLM only provides a portion of that input and we need to manually input the data somehow before executing the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first define our tool which now takes two inputs, and create a binded model for our newly defined tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "@tool\n",
    "def search(query: str, max_results: int):\n",
    "    '''Look things up online'''\n",
    "    return [str(TavilySearchResults(max_results=max_results).invoke(query)).replace('\\'','\\\"')]\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "tool_executor = ToolExecutor(tools)\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True)\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's slightly edit our node function from above to accomodate this change in our tool definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "\n",
    "def execute_search_with_user_input(state: AgentState):\n",
    "    max_results = input(prompt=\"How many search results should we return? Enter a number 1-10\")\n",
    "\n",
    "    if max_results.isdigit() and int(max_results) > 0 and int(max_results) <= 10:\n",
    "        last_message = state['messages'][-1]\n",
    "        tool_call = last_message.tool_calls[0]\n",
    "        action = ToolInvocation(\n",
    "            tool=tool_call[\"name\"],\n",
    "            tool_input={**tool_call[\"args\"],**{'max_results':int(max_results)}},\n",
    "        )\n",
    "        response = tool_executor.invoke(action)\n",
    "        return {'messages':[ToolMessage(content=str(response),tool_call_id=tool_call['id'])]}\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compile the graph just like the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"search\", execute_search_with_user_input)\n",
    "graph.set_entry_point(\"agent\")\n",
    "graph.add_conditional_edges(\"agent\",should_call_tool)\n",
    "graph.add_edge(\"search\",\"agent\")\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='When are the 3 best movies of all time?'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8qU9IsUtmU5c7itdOq1MUMyj', 'function': {'arguments': '{\"query\":\"best movies of all time\",\"max_results\":3}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-1dae89f3-ebec-4057-ad06-87d75a4fafb2-0', tool_calls=[{'name': 'search', 'args': {'query': 'best movies of all time', 'max_results': 3}, 'id': 'call_8qU9IsUtmU5c7itdOq1MUMyj'}]),\n",
       "  ToolMessage(content='[\\'[{\"url\": \"https://www.imdb.com/chart/top/\", \"content\": \"You have rated\\\\\\\\nMore to explore\\\\\\\\nCharts\\\\\\\\nTop Box Office (US)\\\\\\\\nMost Popular Movies\\\\\\\\nTop Rated English Movies\\\\\\\\nMost Popular TV Shows\\\\\\\\nTop 250 TV Shows\\\\\\\\nLowest Rated Movies\\\\\\\\nMost Popular Celebs\\\\\\\\nTop Rated Movies by Genre\\\\\\\\nRecently viewed\\\\\\\\n© 1990-2024 by IMDb.com, Inc. The Lord of the Rings: The Return of the King\\\\\\\\n8. The Lord of the Rings: The Fellowship of the Ring\\\\\\\\n10. Aladdin\\\\\\\\nThe Top Rated Movie list only includes feature films.\\\\\\\\n The Godfather Part II\\\\\\\\n5. 12 Angry Men\\\\\\\\n6.\"}, {\"url\": \"https://editorial.rottentomatoes.com/guide/best-movies-of-all-time/\", \"content\": \"Find out the highest-rated movies of all time according to critics and users on Rotten Tomatoes. Browse the list of 300 films from different genres, years, and countries, and see their scores and summaries.\"}, {\"url\": \"https://variety.com/lists/best-movies-of-all-time/\", \"content\": \"From the awesome glory of the “Also sprach Zarathustra” planetary-alignment prelude to the ape using a bone to discover human intelligence (and violence), from the “Blue Danube” ballet of orbiting satellites to the mission to Jupiter that becomes an outlandishly suspenseful astronaut-versus-computer showdown, from the still-eyeball-blowing psychedelic wormhole climax to the Star Child who is all of us reborn, Kubrick’s trancelike thriller meditation on the place of man in the universe stands as one of cinema’s monolithic achievements.\\\\\\\\n The Sound of Music (1965)\\\\\\\\nJulie Andrews is most famous for two movies, “Mary Poppins” and “The Sound of Music” (made in 1964 and ’65), and her character in the latter film — a nun-turned-governess who looks after the seven Von Trapp children, teaches them to sing and brings them to life, all under the watchful gaze of their stern military father (Christopher Plummer) — is such a goody-two-shoes that her stardom, on occasion, gets mocked and dismissed. For decades it was commonly thought of as the greatest movie ever made, and there are a lot of reasons why: the visionary excitement of it, the through-a-snow-globe-darkly Gothic majesty of it, the joyous acting, the hypnotic structure, the playfulness, the doomy haunting symbolism of Rosebud, and on and on. A three-and-a-half-hour parable spanning 2,000 years and told in four parts (a modern saga of poverty and crime; the story of Jesus; the St. Bartholomew Day’s Massacre; and the fall of the Babylonian empire, complete with elephants), the movie is one of the most soul-boggling spectacles ever attempted: tender, hyperbolic, spellbinding and half-mad. Coppola’s delirious and druggy Vietnam bad trip features one of the greatest sequences ever filmed — the “Ride of the Valkyries” helicopter attack, which channels the adrenalized rush of war that’s inseparable from its horror — and the rest of the movie works on you with a slow-burn hypnosis.\"}]\\']', tool_call_id='call_8qU9IsUtmU5c7itdOq1MUMyj'),\n",
       "  AIMessage(content='The 3 best movies of all time are:\\n\\n1. The Lord of the Rings: The Return of the King\\n2. The Lord of the Rings: The Fellowship of the Ring\\n3. Aladdin\\n\\nThese movies are highly rated and considered among the best of all time.', response_metadata={'finish_reason': 'stop'}, id='run-1a38298a-3c46-420f-bd88-eec9581283b1-0')]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({'messages':[HumanMessage(content=\"When are the 3 best movies of all time?\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we selected 3 search results, but on different runs the user will be able to select any amount of search results they want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-explicit Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some schemas are not explicitly tools, but we can use them to make decisions in our graph, such as what node to proceed to next. Let us define a pydantic model that will inform our node selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingFunction(BaseModel):\n",
    "    \"\"\"Select the next node to proceed to\"\"\"\n",
    "\n",
    "    next_node: str = Field(description=\"The next node to travel to. The options are: node_2 or node_3\")\n",
    "\n",
    "tool_node = ToolNode([RoutingFunction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bind this \"function\" to our model and force it to select the tool, by passing in the param `tool_choice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True)\n",
    "model = model.bind_tools([RoutingFunction],tool_choice=\"RoutingFunction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our new graph, first specifying the functions we will need for each of our nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def node_2_func(state):\n",
    "    return {\"messages\":[SystemMessage(content=f\"I made it to node 2!\")]}\n",
    "\n",
    "def node_3_func(state):\n",
    "    return {\"messages\":[SystemMessage(content=f\"I made it to node 3!\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_which_node(state: AgentState):\n",
    "    return state['messages'][-1].content.split('\\'')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"routing_tool\", tool_node)\n",
    "graph.add_edge(\"agent\",\"routing_tool\")\n",
    "graph.add_node(\"node_2\", node_2_func)\n",
    "graph.add_node(\"node_3\", node_3_func)\n",
    "graph.set_entry_point(\"agent\")\n",
    "graph.add_conditional_edges(\"routing_tool\",select_which_node)\n",
    "graph.add_edge(\"node_2\",END)\n",
    "graph.add_edge(\"node_3\",END)\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Please go to the node with the higher number'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_F2k4ZZxC1gHRv6bdNiRn4m4a', 'function': {'arguments': '{\"next_node\":\"node_3\"}', 'name': 'RoutingFunction'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'stop'}, id='run-f10b8b5e-5d41-43f1-b41c-9046d5bcb24d-0', tool_calls=[{'name': 'RoutingFunction', 'args': {'next_node': 'node_3'}, 'id': 'call_F2k4ZZxC1gHRv6bdNiRn4m4a'}]),\n",
       "  ToolMessage(content=\"next_node='node_3'\", name='RoutingFunction', tool_call_id='call_F2k4ZZxC1gHRv6bdNiRn4m4a'),\n",
       "  SystemMessage(content='I made it to node 3!')]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":[HumanMessage(content=\"Please go to the node with the higher number\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, by using structured output we can select the next node to travel to without having to explicitly state anything."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
