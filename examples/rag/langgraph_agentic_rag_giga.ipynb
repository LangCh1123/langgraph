{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever\n",
    "\n",
    "First, we index 3 blog posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings.gigachat import GigaChatEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "\n",
    "# Используйте токен, полученный в личном кабинете из поля Авторизационные данные\n",
    "_URL_PRO = \"https://wmapi-ift.saluteai-pd.sberdevices.ru/v1/\"\n",
    "\n",
    "def get_giga():\n",
    "    return GigaChat(\n",
    "            base_url=_URL_PRO,\n",
    "            credentials=\"credentials ...\"\n",
    "            )    \n",
    "\n",
    "\n",
    "urls = [\n",
    "    \"https://habr.com/ru/companies/sberdevices/articles/794773/\",\n",
    "    \"https://habr.com/ru/companies/sberdevices/articles/792660/\",\n",
    "    \"https://habr.com/ru/companies/sberdevices/articles/777578/\",\n",
    "    \"https://habr.com/ru/companies/sberbank/articles/773180/\",\n",
    "    \"https://habr.com/ru/companies/sberdevices/articles/790470/\"\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_URL_PLUS = \"https://beta.saluteai.sberdevices.ru/v1\"\n",
    "giga_embeddings = GigaChatEmbeddings(base_url=_URL_PLUS,\n",
    "    credentials=\"credentials ...\")\n",
    "\n",
    "# Add to vectorDB\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=giga_embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a retriever tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Выполняет поиск по статьям про GigaChat на Хабре\",\n",
    ")\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent state\n",
    " \n",
    "We will defined a graph.\n",
    "\n",
    "A `state` object that it passes around to each node.\n",
    "\n",
    "Our state will be a list of `messages`.\n",
    "\n",
    "Each node in our graph will append to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes and Edges\n",
    "\n",
    "We can lay out an agentic RAG graph like this:\n",
    "\n",
    "* The state is a set of messages\n",
    "* Each node will update (append to) state\n",
    "* Conditional edges decide which node to visit next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, Type, TypedDict\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import GigaChat\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.utils.function_calling import convert_to_gigachat_function\n",
    "\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def should_retrieve(state: Type[AgentState]) -> str:\n",
    "    \"\"\"\n",
    "    Decides whether the agent should retrieve more information or end the process.\n",
    "\n",
    "    This function checks the last message in the state for a function call. If a function call is\n",
    "    present, the process continues to retrieve information. Otherwise, it ends the process.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision to either \"continue\" the retrieval process or \"end\" it\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---DECIDE TO RETRIEVE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "\n",
    "    if not isinstance(last_message, BaseMessage):\n",
    "        raise Exception(\"Last message is not a BaseMessage instance\")\n",
    "\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        print(\"---DECISION: DO NOT RETRIEVE / DONE---\")\n",
    "        return \"end\"\n",
    "    # Otherwise there is a function call, so we continue\n",
    "    else:\n",
    "        print(\"---DECISION: RETRIEVE---\")\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state: Type[AgentState]):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    llm = get_giga()\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"Вы — оценщик, оценивающий соответствие полученного документа вопросу пользователя. \\п\n",
    "         Вот полученный документ: \\n\\n {context} \\n\\n\n",
    "         Вот вопрос пользователя: {question} \\n\n",
    "         Если документ содержит ключевые слова или семантическое значение, связанное с вопросом пользователя, оцените его как релевантный. \\п\n",
    "         Дайте двоичную оценку \"yes\" или \"no\", чтобы указать, имеет ли документ отношение к вопросу.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    #chain = prompt | llm_with_tool | parser_tool\n",
    "    chain = prompt | llm\n",
    "\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    print(f\"---CHECKING RELEVANCE FOR DOCS--- last_message={last_message}\")\n",
    "\n",
    "    question = messages[0].content\n",
    "\n",
    "    docs = last_message.content\n",
    "    \n",
    "    score = chain.invoke(\n",
    "        {\"question\": question, \n",
    "         \"context\": docs}\n",
    "    )\n",
    "    print(f\"---SCORE--- {score}\")\n",
    "    \n",
    "\n",
    "    grade = score.content\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(grade)\n",
    "        return \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response apended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    print(\"Agent received:\", messages)\n",
    "    model = get_giga()\n",
    "    \n",
    "    functions = [convert_to_gigachat_function(t) for t in tools]\n",
    "    model = model.bind_functions(functions)\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    \n",
    "    \"\"\"\n",
    "    ----- # due to current code at langchain_community/chat_models/gigachat.py def _convert_dict_to_message(message: Messages) -> BaseMessage:\n",
    "        if not isinstance(response, BaseMessage):\n",
    "        raise Exception(\"Last message is not a BaseMessage instance\")\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" in response.additional_kwargs: \n",
    "        if function_call := response.additional_kwargs[\"function_call\"]:\n",
    "            from gigachat.models.function_call import FunctionCall\n",
    "            if isinstance(function_call, FunctionCall): \n",
    "                response.additional_kwargs[\"function_call\"] = dict(function_call) \n",
    "    \"\"\"\n",
    "    ----- # due to current code at langchain_community/chat_models/gigachat.py def _convert_dict_to_message(message: Messages) -> BaseMessage:\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Uses tool to execute retrieval.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with retrieved docs\n",
    "    \"\"\"\n",
    "    print(\"---EXECUTE RETRIEVAL---\")\n",
    "    messages = state[\"messages\"]\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "\n",
    "    if function_call := last_message.additional_kwargs[\"function_call\"]:\n",
    "        from gigachat.models.function_call import FunctionCall\n",
    "        if isinstance(function_call, FunctionCall): \n",
    "            # due to current code at langchain_community/chat_models/gigachat.py def _convert_dict_to_message(message: Messages) -> BaseMessage:\n",
    "            last_message.additional_kwargs[\"function_call\"] = dict(function_call) \n",
    "\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "    )\n",
    "\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}\n",
    "\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "    \n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "    \n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    question = messages[0].content\n",
    "\n",
    "    print(f\"---TRANSFORM QUERY---messages={messages}\\n-----\\n question={question}\")\n",
    "\n",
    "    msg = [HumanMessage(\n",
    "        content=f\"\"\" \\n \n",
    "        Пользователь ищет информацию в научных статьях. Пользователь формулирует поисковые вопросы к базе знаний.\\n \n",
    "        Здесь изначальный вопрос пользователя:\n",
    "        \\n ------- \\n\n",
    "        {question} \n",
    "        \\n ------- \\n\n",
    "        Перефразируй изначальный вопрос пользователя так, чтобы вопрос был полным, завершенным и точным\"\"\",\n",
    "        )]\n",
    "\n",
    "    # Grader\n",
    "    model = get_giga()\n",
    "    response = model.invoke(msg)\n",
    "     \n",
    "    print(\"---TRANSFROM QUERY RESPONSE--- response =\", response)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "\n",
    "    question = messages[0].content\n",
    "\n",
    "    # LLM\n",
    "    llm = get_giga()\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\", Ты ассистент, который отвечает на вопрос пользователя. \n",
    "            Ответь на вопрос пользователя исходя из контекста.\n",
    "            Если ты не знаешь ответа, просто скажи, что не знаешь, не пытайся придумать ответ. \\п\n",
    "            Вот полученный контекст: \\n\\n {context} \\n\\n\n",
    "            Вот вопрос пользователя: {question} \\n\n",
    "            для ответа на вопрос\n",
    "            \"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm\n",
    "\n",
    "    response = chain.invoke(\n",
    "        {\"question\": question, \n",
    "            \"context\": messages}\n",
    ")\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph\n",
    "\n",
    "* Start with an agent, `call_model`\n",
    "* Agent make a decision to call a function\n",
    "* If so, then `action` to call tool (retriever)\n",
    "* Then call agent with the tool output added to messages (`state`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)  # retrieval\n",
    "workflow.add_node(\"generate\", generate)  # retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call agent node to decide to retrieve or not\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    should_retrieve,\n",
    "    {\n",
    "        # Call tool node\n",
    "        \"continue\": \"retrieve\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    "    {\n",
    "        \"yes\": \"generate\",\n",
    "        \"no\": \"rewrite\",  \n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "def qna(question):\n",
    "    inputs = {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=question\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "    for output in app.stream(inputs):\n",
    "        for key, value in output.items():\n",
    "            pprint.pprint(f\"Output from node '{key}':\")\n",
    "            pprint.pprint(\"---\")\n",
    "            pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "        pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QnA, когда нужен дополнительный поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "Agent received: [HumanMessage(content='Какие определения агентов приводятся в статьях на Хабре?')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'agent':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={'function_call': {'name': 'retrieve_blog_posts', 'arguments': {'query': 'определение агент'}}})]}\n",
      "'\\n---\\n'\n",
      "---DECIDE TO RETRIEVE---\n",
      "---DECISION: RETRIEVE---\n",
      "---EXECUTE RETRIEVAL---\n",
      "\"Output from node 'retrieve':\"\n",
      "'---'\n",
      "{ 'messages': [ FunctionMessage(content=\"Билл Гейтс говорит, что агенты — это тип программного обеспечения, который реагирует на естественный язык и может выполнять множество различных задач на основе знаний пользователя.\\xa0Я бы дополнил определение агентов следующим тезисом:«Агент – это программа, которая способна взаимодействовать с внешней средой с помощью инструментов и корректировать своё поведение в зависимости от результатов\\n\\nи всем распорядком на земле без точного плана на некоторый срок.'}AI-агентыВ завершение хотелось бы немного рассказать про агентов. Все о них говорят, но однозначного понимания того, что такое агент, пока нет. Например, вот так выглядят определения от OpenAI:Системы, которые адаптивно преследуют сложные составные цели, используя рассуждения, и при этом не каждый их шаг контролируется человеком\\n\\nэтом не каждый их шаг контролируется человеком (то есть им предоставляется автономия), а поведение не заложено заранее.или так:Системы, способные на широкий спектр действий и достаточно надежны, чтобы в определенных обстоятельствах пользователь мог доверить им эффективно и автономно выполнять задачи для достижения сложных целей ВМЕСТО пользователя.А Билл Гейтс говорит, что агенты — это тип\\n\\nОбзор\", name='retrieve_blog_posts')]}\n",
      "'\\n---\\n'\n",
      "---CHECKING RELEVANCE FOR DOCS--- last_message=content=\"Билл Гейтс говорит, что агенты — это тип программного обеспечения, который реагирует на естественный язык и может выполнять множество различных задач на основе знаний пользователя.\\xa0Я бы дополнил определение агентов следующим тезисом:«Агент – это программа, которая способна взаимодействовать с внешней средой с помощью инструментов и корректировать своё поведение в зависимости от результатов\\n\\nи всем распорядком на земле без точного плана на некоторый срок.'}AI-агентыВ завершение хотелось бы немного рассказать про агентов. Все о них говорят, но однозначного понимания того, что такое агент, пока нет. Например, вот так выглядят определения от OpenAI:Системы, которые адаптивно преследуют сложные составные цели, используя рассуждения, и при этом не каждый их шаг контролируется человеком\\n\\nэтом не каждый их шаг контролируется человеком (то есть им предоставляется автономия), а поведение не заложено заранее.или так:Системы, способные на широкий спектр действий и достаточно надежны, чтобы в определенных обстоятельствах пользователь мог доверить им эффективно и автономно выполнять задачи для достижения сложных целей ВМЕСТО пользователя.А Билл Гейтс говорит, что агенты — это тип\\n\\nОбзор\" name='retrieve_blog_posts'\n",
      "---SCORE--- content='yes'\n",
      "---DECISION: DOCS RELEVANT---\n",
      "---GENERATE---\n",
      "\"Output from node 'generate':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content='В статьях на Хабре приводятся различные определения агентов. Одно из определений гласит, что агенты - это тип программного обеспечения, которое реагирует на естественный язык и может выполнять множество различных задач на основе знаний пользователя. Другое определение говорит о том, что агенты - это системы, которые адаптивно преследуют сложные составные цели, используя рассуждения, и при этом не каждый их шаг контролируется человеком. Также упоминается определение, согласно которому агенты - это системы, способные на широкий спектр действий и достаточно надежны, чтобы в определенных обстоятельствах пользователь мог доверить им эффективно и автономно выполнять задачи для достижения сложных целей вместо пользователя.')]}\n",
      "'\\n---\\n'\n",
      "\"Output from node '__end__':\"\n",
      "'---'\n",
      "{ 'messages': [ HumanMessage(content='Какие определения агентов приводятся в статьях на Хабре?'),\n",
      "                AIMessage(content='', additional_kwargs={'function_call': {'name': 'retrieve_blog_posts', 'arguments': {'query': 'определение агент'}}}),\n",
      "                FunctionMessage(content=\"Билл Гейтс говорит, что агенты — это тип программного обеспечения, который реагирует на естественный язык и может выполнять множество различных задач на основе знаний пользователя.\\xa0Я бы дополнил определение агентов следующим тезисом:«Агент – это программа, которая способна взаимодействовать с внешней средой с помощью инструментов и корректировать своё поведение в зависимости от результатов\\n\\nи всем распорядком на земле без точного плана на некоторый срок.'}AI-агентыВ завершение хотелось бы немного рассказать про агентов. Все о них говорят, но однозначного понимания того, что такое агент, пока нет. Например, вот так выглядят определения от OpenAI:Системы, которые адаптивно преследуют сложные составные цели, используя рассуждения, и при этом не каждый их шаг контролируется человеком\\n\\nэтом не каждый их шаг контролируется человеком (то есть им предоставляется автономия), а поведение не заложено заранее.или так:Системы, способные на широкий спектр действий и достаточно надежны, чтобы в определенных обстоятельствах пользователь мог доверить им эффективно и автономно выполнять задачи для достижения сложных целей ВМЕСТО пользователя.А Билл Гейтс говорит, что агенты — это тип\\n\\nОбзор\", name='retrieve_blog_posts'),\n",
      "                AIMessage(content='В статьях на Хабре приводятся различные определения агентов. Одно из определений гласит, что агенты - это тип программного обеспечения, которое реагирует на естественный язык и может выполнять множество различных задач на основе знаний пользователя. Другое определение говорит о том, что агенты - это системы, которые адаптивно преследуют сложные составные цели, используя рассуждения, и при этом не каждый их шаг контролируется человеком. Также упоминается определение, согласно которому агенты - это системы, способные на широкий спектр действий и достаточно надежны, чтобы в определенных обстоятельствах пользователь мог доверить им эффективно и автономно выполнять задачи для достижения сложных целей вместо пользователя.')]}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "qna(\"Какие определения агентов приводятся в статьях на Хабре?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QnA, когда дополнительный поиск не требуется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "Agent received: [HumanMessage(content='Что такое ИИ-агент?')]\n",
      "\"Output from node 'agent':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content='ИИ-агент (ИИ — искусственный интеллект) — это компьютерная программа, которая может обучаться и принимать решения подобно человеку.')]}\n",
      "'\\n---\\n'\n",
      "---DECIDE TO RETRIEVE---\n",
      "---DECISION: DO NOT RETRIEVE / DONE---\n",
      "\"Output from node '__end__':\"\n",
      "'---'\n",
      "{ 'messages': [ HumanMessage(content='Что такое ИИ-агент?'),\n",
      "                AIMessage(content='ИИ-агент (ИИ — искусственный интеллект) — это компьютерная программа, которая может обучаться и принимать решения подобно человеку.')]}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "qna(\"Что такое ИИ-агент?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
