{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53",
   "metadata": {},
   "source": [
    "# Persistence with Postgres\n",
    "\n",
    ":::note\n",
    "The langchain-postgres package has not kept up-to-date with the LangGraph package. While we work to make improvements, we will leave the following code for historic context.\n",
    ":::\n",
    "\n",
    "When creating LangGraph agents, you can also set them up so that they persist their state. This allows you to do things like interact with an agent multiple times and have it remember previous interactions.\n",
    "\n",
    "This example shows how to use `Postgres` as the backend for persisting checkpoint state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2309ea5d-7c8c-4028-89fe-39aa9843ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from typing import Any, AsyncGenerator, AsyncIterator, Generator, Optional, Union, Tuple\n",
    "\n",
    "import psycopg\n",
    "from psycopg.types.json import Jsonb\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint import BaseCheckpointSaver\n",
    "from langgraph.serde.jsonplus import JsonPlusSerializer\n",
    "from langgraph.checkpoint.base import Checkpoint, CheckpointMetadata, CheckpointTuple\n",
    "from psycopg_pool import AsyncConnectionPool, ConnectionPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a35dba8e-5562-4803-ad80-160f53592dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation of a langgraph checkpoint saver using Postgres.\"\"\"\n",
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from typing import Any, AsyncGenerator, AsyncIterator, Generator, Optional, Union, Tuple, List\n",
    "\n",
    "import psycopg\n",
    "from psycopg.types.json import Jsonb\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint import BaseCheckpointSaver\n",
    "from langgraph.serde.jsonplus import JsonPlusSerializer\n",
    "from langgraph.checkpoint.base import Checkpoint, CheckpointMetadata, CheckpointTuple\n",
    "from psycopg_pool import AsyncConnectionPool, ConnectionPool\n",
    "\n",
    "\n",
    "class JsonAndBinarySerializer(JsonPlusSerializer):\n",
    "    def _default(self, obj):\n",
    "        if isinstance(obj, (bytes, bytearray)):\n",
    "            return self._encode_constructor_args(\n",
    "                obj.__class__, method=\"fromhex\", args=[obj.hex()]\n",
    "            )\n",
    "        return super()._default(obj)\n",
    "\n",
    "    def dumps(self, obj: Any) -> tuple[str, bytes]:\n",
    "        if isinstance(obj, bytes):\n",
    "            return \"bytes\", obj\n",
    "        elif isinstance(obj, bytearray):\n",
    "            return \"bytearray\", obj\n",
    "\n",
    "        return \"json\", super().dumps(obj)\n",
    "\n",
    "    def loads(self, s: tuple[str, bytes]) -> Any:\n",
    "        if s[0] == \"bytes\":\n",
    "            return s[1]\n",
    "        elif s[0] == \"bytearray\":\n",
    "            return bytearray(s[1])\n",
    "        elif s[0] == \"json\":\n",
    "            return super().loads(s[1])\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown serialization type: {s[0]}\")\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def _get_sync_connection(\n",
    "    connection: Union[psycopg.Connection, ConnectionPool, None],\n",
    ") -> Generator[psycopg.Connection, None, None]:\n",
    "    \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "    if isinstance(connection, psycopg.Connection):\n",
    "        yield connection\n",
    "    elif isinstance(connection, ConnectionPool):\n",
    "        with connection.connection() as conn:\n",
    "            yield conn\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid sync connection object. Please initialize the check pointer \"\n",
    "            f\"with an appropriate sync connection object. \"\n",
    "            f\"Got {type(connection)}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def _get_async_connection(\n",
    "    connection: Union[psycopg.AsyncConnection, AsyncConnectionPool, None],\n",
    ") -> AsyncGenerator[psycopg.AsyncConnection, None]:\n",
    "    \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "    if isinstance(connection, psycopg.AsyncConnection):\n",
    "        yield connection\n",
    "    elif isinstance(connection, AsyncConnectionPool):\n",
    "        async with connection.connection() as conn:\n",
    "            yield conn\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid async connection object. Please initialize the check pointer \"\n",
    "            f\"with an appropriate async connection object. \"\n",
    "            f\"Got {type(connection)}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "class PostgresSaver(BaseCheckpointSaver):\n",
    "    \"\"\"LangGraph checkpoint saver for Postgres.\n",
    "    This implementation of a checkpoint saver uses a Postgres database to save\n",
    "    and retrieve checkpoints. It uses the psycopg3 package to interact with the\n",
    "    Postgres database.\n",
    "    The checkpoint accepts either a sync_connection in the form of a psycopg.Connection\n",
    "    or a psycopg.ConnectionPool object, or an async_connection in the form of a\n",
    "    psycopg.AsyncConnection or psycopg.AsyncConnectionPool object.\n",
    "    Usage:\n",
    "    1. First time use: create schema in the database using the `create_tables` method or\n",
    "       the async version `acreate_tables` method.\n",
    "    2. Create a PostgresCheckpoint object with a serializer and an appropriate\n",
    "       connection object.\n",
    "       It's recommended to use a connection pool object for the connection.\n",
    "       If using a connection object, you are responsible for closing the connection\n",
    "       when done.\n",
    "    Examples:\n",
    "    Sync usage with a connection pool:\n",
    "        .. code-block:: python\n",
    "            from psycopg_pool import ConnectionPool\n",
    "            from langchain_postgres import (\n",
    "                PostgresCheckpoint, PickleCheckpointSerializer\n",
    "            )\n",
    "            pool = ConnectionPool(\n",
    "                # Example configuration\n",
    "                conninfo=\"postgresql://user:password@localhost:5432/dbname\",\n",
    "                max_size=20,\n",
    "            )\n",
    "            # Uses the pickle module for serialization\n",
    "            # Make sure that you're only de-serializing trusted data\n",
    "            # (e.g., payloads that you have serialized yourself).\n",
    "            # Or implement a custom serializer.\n",
    "            checkpoint = PostgresCheckpoint(\n",
    "                serializer=PickleCheckpointSerializer(),\n",
    "                sync_connection=pool,\n",
    "            )\n",
    "            # Use the checkpoint object to put, get, list checkpoints, etc.\n",
    "    Async usage with a connection pool:\n",
    "        .. code-block:: python\n",
    "            from psycopg_pool import AsyncConnectionPool\n",
    "            from langchain_postgres import (\n",
    "                PostgresCheckpoint, PickleCheckpointSerializer\n",
    "            )\n",
    "            pool = AsyncConnectionPool(\n",
    "                # Example configuration\n",
    "                conninfo=\"postgresql://user:password@localhost:5432/dbname\",\n",
    "                max_size=20,\n",
    "            )\n",
    "            # Uses the pickle module for serialization\n",
    "            # Make sure that you're only de-serializing trusted data\n",
    "            # (e.g., payloads that you have serialized yourself).\n",
    "            # Or implement a custom serializer.\n",
    "            checkpoint = PostgresCheckpoint(\n",
    "                serializer=PickleCheckpointSerializer(),\n",
    "                async_connection=pool,\n",
    "            )\n",
    "            # Use the checkpoint object to put, get, list checkpoints, etc.\n",
    "    Async usage with a connection object:\n",
    "        .. code-block:: python\n",
    "            from psycopg import AsyncConnection\n",
    "            from langchain_postgres import (\n",
    "                PostgresCheckpoint, PickleCheckpointSerializer\n",
    "            )\n",
    "            conninfo=\"postgresql://user:password@localhost:5432/dbname\"\n",
    "            # Take care of closing the connection when done\n",
    "            async with AsyncConnection(conninfo=conninfo) as conn:\n",
    "                # Uses the pickle module for serialization\n",
    "                # Make sure that you're only de-serializing trusted data\n",
    "                # (e.g., payloads that you have serialized yourself).\n",
    "                # Or implement a custom serializer.\n",
    "                checkpoint = PostgresCheckpoint(\n",
    "                    serializer=PickleCheckpointSerializer(),\n",
    "                    async_connection=conn,\n",
    "                )\n",
    "                # Use the checkpoint object to put, get, list checkpoints, etc.\n",
    "                ...\n",
    "    \"\"\"\n",
    "\n",
    "    sync_connection: Optional[Union[psycopg.Connection, ConnectionPool]] = None\n",
    "    \"\"\"The synchronous connection or pool to the Postgres database.\n",
    "    \n",
    "    If providing a connection object, please ensure that the connection is open\n",
    "    and remember to close the connection when done.\n",
    "    \"\"\"\n",
    "    async_connection: Optional[\n",
    "        Union[psycopg.AsyncConnection, AsyncConnectionPool]\n",
    "    ] = None\n",
    "    \"\"\"The asynchronous connection or pool to the Postgres database.\n",
    "    \n",
    "    If providing a connection object, please ensure that the connection is open\n",
    "    and remember to close the connection when done.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sync_connection: Optional[Union[psycopg.Connection, ConnectionPool]] = None,\n",
    "        async_connection: Optional[\n",
    "            Union[psycopg.AsyncConnection, AsyncConnectionPool]\n",
    "        ] = None\n",
    "        \n",
    "    ):\n",
    "        super().__init__(serde=JsonPlusSerializer())\n",
    "        self.sync_connection = sync_connection\n",
    "        self.async_connection = async_connection\n",
    "\n",
    "    @contextmanager\n",
    "    def _get_sync_connection(self) -> Generator[psycopg.Connection, None, None]:\n",
    "        \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "        with _get_sync_connection(self.sync_connection) as connection:\n",
    "            yield connection\n",
    "\n",
    "    @asynccontextmanager\n",
    "    async def _get_async_connection(\n",
    "        self,\n",
    "    ) -> AsyncGenerator[psycopg.AsyncConnection, None]:\n",
    "        \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "        async with _get_async_connection(self.async_connection) as connection:\n",
    "            yield connection\n",
    "\n",
    "    @staticmethod\n",
    "    def create_tables(connection: Union[psycopg.Connection, ConnectionPool], /) -> None:\n",
    "        \"\"\"Create the schema for the checkpoint saver.\"\"\"\n",
    "        with _get_sync_connection(connection) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS checkpoints (\n",
    "                        thread_id TEXT NOT NULL,\n",
    "                        thread_ts TIMESTAMPTZ NOT NULL,\n",
    "                        parent_ts TIMESTAMPTZ,\n",
    "                        checkpoint BYTEA NOT NULL,\n",
    "                        metadata BYTEA NOT NULL,\n",
    "                        PRIMARY KEY (thread_id, thread_ts)\n",
    "                    );\n",
    "                    \"\"\"\n",
    "                )\n",
    "\n",
    "    @staticmethod\n",
    "    async def acreate_tables(\n",
    "        connection: Union[psycopg.AsyncConnection, AsyncConnectionPool], /\n",
    "    ) -> None:\n",
    "        \"\"\"Create the schema for the checkpoint saver.\"\"\"\n",
    "        async with _get_async_connection(connection) as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.execute(\n",
    "                    \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS checkpoints (\n",
    "                        thread_id TEXT NOT NULL,\n",
    "                        thread_ts TIMESTAMPTZ NOT NULL,\n",
    "                        parent_ts TIMESTAMPTZ,\n",
    "                        checkpoint BYTEA NOT NULL,\n",
    "                        metadata BYTEA NOT NULL,\n",
    "                        PRIMARY KEY (thread_id, thread_ts)\n",
    "                    );\n",
    "                    \"\"\"\n",
    "                )\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_tables(connection: psycopg.Connection, /) -> None:\n",
    "        \"\"\"Drop the table for the checkpoint saver.\"\"\"\n",
    "        with connection.cursor() as cur:\n",
    "            cur.execute(\"DROP TABLE IF EXISTS checkpoints;\")\n",
    "\n",
    "    @staticmethod\n",
    "    async def adrop_tables(connection: psycopg.AsyncConnection, /) -> None:\n",
    "        \"\"\"Drop the table for the checkpoint saver.\"\"\"\n",
    "        async with connection.cursor() as cur:\n",
    "            await cur.execute(\"DROP TABLE IF EXISTS checkpoints;\")\n",
    "\n",
    "    def put(self, config: RunnableConfig, checkpoint: Checkpoint, metadata: CheckpointMetadata) -> RunnableConfig:\n",
    "        \"\"\"Put the checkpoint for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "            checkpoint: The checkpoint to persist.\n",
    "        Returns:\n",
    "            The RunnableConfig that describes the checkpoint that was just created.\n",
    "            It'll contain the `thread_id` and `thread_ts` of the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        print((\n",
    "                        thread_id,\n",
    "                        checkpoint[\"ts\"],\n",
    "                        config[\"configurable\"].get(\"thread_ts\"),\n",
    "                        self.serde.dumps(checkpoint),\n",
    "                        self.serde.dumps(metadata),\n",
    "                    )\n",
    "        )\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(\n",
    "                     \"\"\"\n",
    "                    INSERT INTO checkpoints \n",
    "                        (thread_id, thread_ts, parent_ts, checkpoint, metadata)\n",
    "                    VALUES \n",
    "                        (%s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT (thread_id, thread_ts)\n",
    "                    DO UPDATE SET checkpoint = EXCLUDED.checkpoint,\n",
    "                                  metadata = EXCLUDED.metadata;\n",
    "                    \"\"\",\n",
    "                    (\n",
    "                        thread_id,\n",
    "                        checkpoint[\"ts\"],\n",
    "                        parent_ts if parent_ts else None,\n",
    "                        self.serde.dumps(checkpoint),\n",
    "                        self.serde.dumps(metadata),\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": checkpoint[\"ts\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    async def aput(\n",
    "        self, config: RunnableConfig, checkpoint: Checkpoint, metadata: CheckpointMetadata\n",
    "    ) -> RunnableConfig:\n",
    "        \"\"\"Put the checkpoint for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "            checkpoint: The checkpoint to persist.\n",
    "        Returns:\n",
    "            The RunnableConfig that describes the checkpoint that was just created.\n",
    "            It'll contain the `thread_id` and `thread_ts` of the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO checkpoints \n",
    "                        (thread_id, thread_ts, parent_ts, checkpoint, metadata)\n",
    "                    VALUES \n",
    "                        (%s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT (thread_id, thread_ts) \n",
    "                    DO UPDATE SET checkpoint = EXCLUDED.checkpoint,\n",
    "                                  metadata = EXCLUDED.metadata;\n",
    "                    \"\"\",\n",
    "                    (\n",
    "                        thread_id,\n",
    "                        checkpoint[\"ts\"],\n",
    "                        parent_ts if parent_ts else None,\n",
    "                        checkpoint,\n",
    "                        metadata,\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": checkpoint[\"ts\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def list(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        *,\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> Generator[CheckpointTuple, None, None]:\n",
    "        \"\"\"Get all the checkpoints for the given configuration.\"\"\"\n",
    "        where, args = self._search_where(config, filter, before)\n",
    "        query = (\n",
    "            \"\"\"\n",
    "            SELECT checkpoint, thread_ts, parent_ts\n",
    "            FROM checkpoints\n",
    "            {where}\n",
    "            ORDER BY thread_ts DESC\n",
    "            \"\"\"\n",
    "        )\n",
    "        if limit:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "                cur.execute(\n",
    "                    query, \n",
    "                    {\n",
    "                        \"thread_id\": thread_id,\n",
    "                    },\n",
    "                )\n",
    "                for value in cur:\n",
    "                    yield CheckpointTuple(\n",
    "                        {\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": value[1].isoformat(),\n",
    "                            }\n",
    "                        },\n",
    "                        self.serde.loads(value[0]),\n",
    "                        {\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": value[2].isoformat(),\n",
    "                            }\n",
    "                        }\n",
    "                        if value[2]\n",
    "                        else None,\n",
    "                    )\n",
    "\n",
    "    async def alist(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        *,\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> AsyncIterator[CheckpointTuple]:\n",
    "        \"\"\"Get all the checkpoints for the given configuration.\"\"\"\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "                await cur.execute(\n",
    "                    \"SELECT checkpoint, thread_ts, parent_ts \"\n",
    "                    \"FROM checkpoints \"\n",
    "                    \"WHERE thread_id = %(thread_id)s \"\n",
    "                    \"ORDER BY thread_ts DESC\",\n",
    "                    {\n",
    "                        \"thread_id\": thread_id,\n",
    "                    },\n",
    "                )\n",
    "                async for value in cur:\n",
    "                    yield CheckpointTuple(\n",
    "                        {\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": value[1].isoformat(),\n",
    "                            }\n",
    "                        },\n",
    "                        self.serde.loads(value[0]),\n",
    "                        {\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": value[2].isoformat(),\n",
    "                            }\n",
    "                        }\n",
    "                        if value[2]\n",
    "                        else None,\n",
    "                    )\n",
    "\n",
    "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get the checkpoint tuple for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "        Returns:\n",
    "            The checkpoint tuple for the given configuration if it exists,\n",
    "            otherwise None.\n",
    "            If thread_ts is None, the latest checkpoint is returned if it exists.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                if thread_ts:\n",
    "                    cur.execute(\n",
    "                        \"SELECT checkpoint, metadata, thread_ts, parent_ts \"\n",
    "                        \"FROM checkpoints \"\n",
    "                        \"WHERE thread_id = %(thread_id)s AND thread_ts = %(thread_ts)s\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"thread_ts\": thread_ts,\n",
    "                        },\n",
    "                    )\n",
    "                    value = cur.fetchone()\n",
    "                    if value:\n",
    "                        checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    return CheckpointTuple(\n",
    "                            config=config,\n",
    "                            checkpoint=self.serde.loads(checkpoint),\n",
    "                            metadata=self.serde.loads(metadata),\n",
    "                            parent_config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": thread_ts.isoformat(),\n",
    "                                }\n",
    "                            }\n",
    "                            if thread_ts\n",
    "                            else None,\n",
    "                        )\n",
    "                else:\n",
    "                    cur.execute(\n",
    "                        \"SELECT checkpoint, metadata, thread_ts, parent_ts \"\n",
    "                        \"FROM checkpoints \"\n",
    "                        \"WHERE thread_id = %(thread_id)s \"\n",
    "                        \"ORDER BY thread_ts DESC LIMIT 1\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                        },\n",
    "                    )\n",
    "                    value = cur.fetchone()\n",
    "                    if value:\n",
    "                        checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                        return CheckpointTuple(\n",
    "                            config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": thread_ts.isoformat(),\n",
    "                                }\n",
    "                            },\n",
    "                            checkpoint=self.serde.loads(checkpoint),\n",
    "                            metadata=self.serde.loads(metadata),\n",
    "                            parent_config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": parent_ts.isoformat(),\n",
    "                                }\n",
    "                            }\n",
    "                            if parent_ts\n",
    "                            else None,\n",
    "                        )\n",
    "        return None\n",
    "\n",
    "    async def aget_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get the checkpoint tuple for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "        Returns:\n",
    "            The checkpoint tuple for the given configuration if it exists,\n",
    "            otherwise None.\n",
    "            If thread_ts is None, the latest checkpoint is returned if it exists.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                if thread_ts:\n",
    "                    await cur.execute(\n",
    "                        \"SELECT checkpoint, parent_ts \"\n",
    "                        \"FROM checkpoints \"\n",
    "                        \"WHERE thread_id = %(thread_id)s AND thread_ts = %(thread_ts)s\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"thread_ts\": thread_ts,\n",
    "                        },\n",
    "                    )\n",
    "                    value = await cur.fetchone()\n",
    "                    if value:\n",
    "                        return CheckpointTuple(\n",
    "                            config,\n",
    "                            self.serde.loads(value[0]),\n",
    "                            {\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": value[1].isoformat(),\n",
    "                                }\n",
    "                            }\n",
    "                            if value[1]\n",
    "                            else None,\n",
    "                        )\n",
    "                else:\n",
    "                    await cur.execute(\n",
    "                        \"SELECT checkpoint, thread_ts, parent_ts \"\n",
    "                        \"FROM checkpoints \"\n",
    "                        \"WHERE thread_id = %(thread_id)s \"\n",
    "                        \"ORDER BY thread_ts DESC LIMIT 1\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                        },\n",
    "                    )\n",
    "                    value = await cur.fetchone()\n",
    "                    if value:\n",
    "                        return CheckpointTuple(\n",
    "                            config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": value[1].isoformat(),\n",
    "                                }\n",
    "                            },\n",
    "                            checkpoint=self.serde.loads(value[0]),\n",
    "                            parent_config={\n",
    "                                \"configurable\": {\n",
    "                                    \"thread_id\": thread_id,\n",
    "                                    \"thread_ts\": value[2].isoformat(),\n",
    "                                }\n",
    "                            }\n",
    "                            if value[2]\n",
    "                            else None,\n",
    "                        )\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def _search_where(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        filter: Optional[dict[str, Any]],\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "    ) -> Tuple[str, List[Any]]:\n",
    "        \"\"\"Return WHERE clause predicates for alist() given config, filter, cursor.\n",
    "\n",
    "        This method returns a tuple of a string and a tuple of values. The string\n",
    "        is the parametered WHERE clause predicate (including the WHERE keyword):\n",
    "        \"WHERE column1 = $1 AND column2 IS $2\". The list of values contains the\n",
    "        values for each of the corresponding parameters.\n",
    "        \"\"\"\n",
    "        wheres = []\n",
    "        param_values = []\n",
    "\n",
    "        # construct predicate for config filter\n",
    "        if config:\n",
    "            wheres.append(\"thread_id = %s \")\n",
    "            param_values.append(config[\"configurable\"][\"thread_id\"])\n",
    "\n",
    "        # construct predicate for metadata filter\n",
    "        if filter:\n",
    "            wheres.append(\"metadata @> %s \")\n",
    "            param_values.append(Jsonb(filter))\n",
    "\n",
    "        # construct predicate for `before`\n",
    "        if before is not None:\n",
    "            wheres.append(\"checkpoint_id < %s \")\n",
    "            param_values.append(before[\"configurable\"][\"thread_ts\"])\n",
    "\n",
    "        return (\n",
    "            \"WHERE \" + \" AND \".join(wheres) if wheres else \"\",\n",
    "            param_values,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce019f5b-b845-4f35-a60a-1652aea8ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make our checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f5bb752-2db2-4eeb-9ca8-7a93c94ea265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import AsyncConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eca9aafb-a155-407a-8036-682a2f1297d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5213193-5a7d-43e7-aeba-fe732bb1cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is all that's needed for the agent.py\n",
    "from typing import Literal\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67425fa3-4686-485b-aa54-8c61729ea9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('json', b'{\"a\": 1}')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer.serde.dumps({'a': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dd1c19bb-a86d-49d7-b1e4-b9d71c92c3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', '2024-06-26T19:13:47.656793+00:00', '2024-06-26T19:12:17.471179+00:00', b'{\"v\": 1, \"ts\": \"2024-06-26T19:13:47.656793+00:00\", \"id\": \"1ef33f03-6d05-6ff2-8001-7f4d2a082b80\", \"channel_values\": {\"messages\": [], \"__start__\": {\"messages\": [[\"human\", \"hi\"]]}}, \"channel_versions\": {\"__start__\": 3}, \"versions_seen\": {\"__start__\": {\"__start__\": 2}, \"agent\": {}, \"tools\": {}}, \"pending_sends\": []}', b'{\"source\": \"input\", \"step\": 1, \"writes\": {\"messages\": [[\"human\", \"hi\"]]}}')\n",
      "('1', '2024-06-26T19:13:47.660001+00:00', '1ef33f03-6d05-6ff2-8001-7f4d2a082b80', b'{\"v\": 1, \"ts\": \"2024-06-26T19:13:47.660001+00:00\", \"id\": \"1ef33f03-6d0d-6d4c-8002-7917eba194e4\", \"channel_values\": {\"messages\": [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"hi\", \"type\": \"human\", \"id\": \"0e59579f-6060-47f0-abe8-be31e4b208c5\"}}], \"start:agent\": \"__start__\"}, \"channel_versions\": {\"__start__\": 4, \"messages\": 4, \"start:agent\": 4}, \"versions_seen\": {\"__start__\": {\"__start__\": 3}, \"agent\": {}, \"tools\": {}}, \"pending_sends\": []}', b'{\"source\": \"loop\", \"step\": 2, \"writes\": null}')\n",
      "('1', '2024-06-26T19:13:48.197984+00:00', '1ef33f03-6d0d-6d4c-8002-7917eba194e4', b'{\"v\": 1, \"ts\": \"2024-06-26T19:13:48.197984+00:00\", \"id\": \"1ef33f03-722f-65e6-8003-9cdd76f93018\", \"channel_values\": {\"messages\": [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"hi\", \"type\": \"human\", \"id\": \"0e59579f-6060-47f0-abe8-be31e4b208c5\"}}, {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"AIMessage\"], \"kwargs\": {\"content\": \"Hello! How can I assist you today?\", \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 10, \"prompt_tokens\": 52, \"total_tokens\": 62}, \"model_name\": \"gpt-4o-2024-05-13\", \"system_fingerprint\": \"fp_4008e3b719\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"id\": \"run-60c9d990-d0f1-4595-a84c-d97b66520f6d-0\", \"usage_metadata\": {\"input_tokens\": 52, \"output_tokens\": 10, \"total_tokens\": 62}, \"tool_calls\": [], \"invalid_tool_calls\": []}}], \"agent\": \"agent\"}, \"channel_versions\": {\"__start__\": 4, \"messages\": 5, \"start:agent\": 5, \"agent\": 5}, \"versions_seen\": {\"__start__\": {\"__start__\": 3}, \"agent\": {\"start:agent\": 4}, \"tools\": {}}, \"pending_sends\": []}', b'{\"source\": \"loop\", \"step\": 3, \"writes\": {\"agent\": {\"messages\": [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"AIMessage\"], \"kwargs\": {\"content\": \"Hello! How can I assist you today?\", \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 10, \"prompt_tokens\": 52, \"total_tokens\": 62}, \"model_name\": \"gpt-4o-2024-05-13\", \"system_fingerprint\": \"fp_4008e3b719\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"id\": \"run-60c9d990-d0f1-4595-a84c-d97b66520f6d-0\", \"usage_metadata\": {\"input_tokens\": 52, \"output_tokens\": 10, \"total_tokens\": 62}, \"tool_calls\": [], \"invalid_tool_calls\": []}}]}}}')\n"
     ]
    },
    {
     "ename": "InvalidDatetimeFormat",
     "evalue": "invalid input syntax for type timestamp with time zone: \"1ef33f03-6d0d-6d4c-8002-7917eba194e4\"\nCONTEXT:  unnamed portal parameter $3 = '...'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidDatetimeFormat\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m graph \u001b[38;5;241m=\u001b[39m create_react_agent(model, tools\u001b[38;5;241m=\u001b[39mtools, checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer)   \n\u001b[1;32m     14\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[0;32m---> 15\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/langgraph/libs/langgraph/langgraph/pregel/__init__.py:1550\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1549\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1550\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/development/langgraph/libs/langgraph/langgraph/pregel/__init__.py:1156\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1152\u001b[0m done, _ \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m   1153\u001b[0m     bg, return_when\u001b[38;5;241m=\u001b[39mconcurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mALL_COMPLETED\n\u001b[1;32m   1154\u001b[0m )\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m done:\n\u001b[0;32m-> 1156\u001b[0m     \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[93], line 270\u001b[0m, in \u001b[0;36mPostgresSaver.put\u001b[0;34m(self, config, checkpoint, metadata)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sync_connection() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[0;32m--> 270\u001b[0m         \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250;43m             \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;43;03m            INSERT INTO checkpoints \u001b[39;49;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;43;03m                (thread_id, thread_ts, parent_ts, checkpoint, metadata)\u001b[39;49;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;43;03m            VALUES \u001b[39;49;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;43;03m                (%s, %s, %s, %s, %s)\u001b[39;49;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;43;03m            ON CONFLICT (thread_id, thread_ts)\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;43;03m            DO UPDATE SET checkpoint = EXCLUDED.checkpoint,\u001b[39;49;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;43;03m                          metadata = EXCLUDED.metadata;\u001b[39;49;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;43;03m            \"\"\"\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m                \u001b[49m\u001b[43mparent_ts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparent_ts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: thread_id,\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_ts\u001b[39m\u001b[38;5;124m\"\u001b[39m: checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    293\u001b[0m     },\n\u001b[1;32m    294\u001b[0m }\n",
      "File \u001b[0;32m~/.virtualenvs/langgraph-postgres/lib/python3.11/site-packages/psycopg/cursor.py:732\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, query, params, prepare, binary)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    729\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_gen(query, params, prepare\u001b[38;5;241m=\u001b[39mprepare, binary\u001b[38;5;241m=\u001b[39mbinary)\n\u001b[1;32m    730\u001b[0m         )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m e\u001b[38;5;241m.\u001b[39m_NO_TRACEBACK \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mInvalidDatetimeFormat\u001b[0m: invalid input syntax for type timestamp with time zone: \"1ef33f03-6d0d-6d4c-8002-7917eba194e4\"\nCONTEXT:  unnamed portal parameter $3 = '...'"
     ]
    }
   ],
   "source": [
    "from psycopg_pool import ConnectionPool\n",
    "\n",
    "pool = ConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=\"postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable\",\n",
    "    max_size=20,\n",
    ")\n",
    "\n",
    "checkpointer = PostgresSaver(\n",
    "    sync_connection=pool\n",
    ")\n",
    "checkpointer.create_tables(pool)\n",
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)   \n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "res = graph.invoke({\"messages\": [(\"human\", \"hi\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591e199a-6d37-4903-a495-7e5f1e2e3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is all that's needed for the agent.py\n",
    "from typing import Literal\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "graph = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1f2c8-b74b-4ff1-ae2b-be273e8fe0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1186aa9b-cf13-4922-95d9-850252b70fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is all that's needed for the agent.py\n",
    "from typing import Literal\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "graph = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ce9fd-d11a-48d4-9a6f-7079ff32400b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f510d-3360-498f-bfff-5666d09652cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conninfo = \"postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable\"\n",
    "# Take care of closing the connection when done\n",
    "async with await AsyncConnection.connect(conninfo) as conn:\n",
    "    checkpointer = PostgresSaver(\n",
    "        async_connection=conn\n",
    "    )\n",
    "    await checkpointer.acreate_tables(conn)\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)    \n",
    "    config = {\"configurable\": {\"thread_id\": 1}}\n",
    "    res = await graph.ainvoke({\"messages\": [(\"human\", \"hi\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d849b5f-1030-4a54-b5d9-2045271149f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-postgres",
   "language": "python",
   "name": "langgraph-postgres"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
