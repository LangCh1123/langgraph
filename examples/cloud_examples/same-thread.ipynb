{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c0837d-c40a-4209-9f88-5d08c00c31b0",
   "metadata": {},
   "source": [
    "# How to run multiple agents on the same thread\n",
    "\n",
    "In LangGraph Cloud, a thread is not explicitly associated with a particular agent.\n",
    "This means that you can run multiple agents on the same thread, which allows a different\n",
    "agent to continue from an initial agent's progress.\n",
    "\n",
    "In this example, we will create two agents and then call them both on the same thread.\n",
    "You'll see that the second agent will respond using information from the [checkpoint](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer-state) generated in the thread\n",
    "by the first agent as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06be1f6-07a5-4e93-8497-02473fc65d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "client = get_client()\n",
    "\n",
    "openai_assistant = await client.assistants.create(\n",
    "    graph_id=\"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n",
    ")\n",
    "\n",
    "# There should always be a default assistant with no configuration\n",
    "assistants = await client.assistants.search()\n",
    "default_assistant = [a for a in assistants if not a[\"config\"]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10d346-69e6-44f4-8ff0-ef539ba938df",
   "metadata": {},
   "source": [
    "We can see that these agents are different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3898ca35-eb2c-4b12-97ea-e0cc6a7c6a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': '13ecc353-a9a9-474b-a824-b6a343cd74b1',\n",
       " 'graph_id': 'agent',\n",
       " 'config': {'configurable': {'model_name': 'openai'}},\n",
       " 'created_at': '2024-05-21T16:22:59.258447+00:00',\n",
       " 'updated_at': '2024-05-21T16:22:59.258447+00:00',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fa67b2-cb4f-43d3-a1fc-f8b3936c16b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'config': {},\n",
       " 'created_at': '2024-05-18T00:19:39.688822+00:00',\n",
       " 'updated_at': '2024-05-18T00:19:39.688822+00:00',\n",
       " 'metadata': {'created_by': 'system'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e655e61-c2ee-488a-90f6-6189c84841da",
   "metadata": {},
   "source": [
    "We can now run the OpenAI assistant on the thread first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ed7a1b-74be-4560-8c55-c76d49d3d348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': 'f90b3029-8669-4d70-976c-b70368e355d8'})\n",
      "StreamPart(event='updates', data={'agent': {'messages': [{'content': 'I was created by OpenAI, a research organization focused on developing and advancing artificial intelligence technology.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop'}, 'type': 'ai', 'name': None, 'id': 'run-9801a5ba-2f3c-43de-89cf-c740debf36fc', 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}]}})\n",
      "StreamPart(event='end', data=None)\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input = {\"messages\": [{\"role\": \"user\", \"content\": \"who made you?\"}]}\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    openai_assistant[\"assistant_id\"],\n",
    "    input=input,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53709e9-ddb2-4429-9042-456eb6c91244",
   "metadata": {},
   "source": [
    "Now, we can run it on a second Anthropic-based assistant and see that this second assistant is aware of the initial question, and can answer the question, `and you?`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "666d78f1-019a-433e-839e-52d2ebb3d9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': 'c3521302-48ae-4c29-a0f2-5eb865cbc6d7'})\n",
      "StreamPart(event='updates', data={'agent': {'messages': [{'content': \"I am an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't actually have a physical form or visual representation - I exist as a language model trained to have natural conversations.\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-4d05ffd7-0505-43e1-a068-0207c56b7665', 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}]}})\n",
      "StreamPart(event='end', data=None)\n"
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [{\"role\": \"user\", \"content\": \"and you?\"}]}\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    default_assistant[\"assistant_id\"],\n",
    "    input=input,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
